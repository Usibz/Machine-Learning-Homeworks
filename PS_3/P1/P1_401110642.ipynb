{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l8KGbM_biRpY"
   },
   "source": [
    "<b><h4>HW3 - Notebook: Multi-Layer perceptron</h4></b>\n",
    "\n",
    "[CE40477: Machine Learning](https://www.sharifml.ir/)\n",
    "\n",
    "__Course Instructor__: Dr. Sharifi-Zarchi\n",
    "\n",
    "__Notebook Authors__: Amir Ezzati & Ali Bavafa\n",
    "\n",
    "Name: Yousef Miryousefi                  \n",
    "Student-ID: 401110642"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3D-dKQK9RSV"
   },
   "source": [
    "# Import & Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Mi1fqVs9jOfx",
    "ExecuteTime": {
     "end_time": "2024-12-06T18:58:17.979907800Z",
     "start_time": "2024-12-06T18:58:17.898146800Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gdown\n",
    "from sklearn.datasets import fetch_openml\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2xc-dSl8s6Jz",
    "outputId": "de90c08d-848e-4e81-845c-5b7ade83593b",
    "ExecuteTime": {
     "end_time": "2024-12-06T18:58:18.023775Z",
     "start_time": "2024-12-06T18:58:17.915154200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed 2024 has been set.\n"
     ]
    }
   ],
   "source": [
    "def seed_setter(seed=None, seed_torch=True):\n",
    "  \"\"\"\n",
    "  Function that controls randomness.\n",
    "\n",
    "  Args:\n",
    "    seed : Integer\n",
    "      A non-negative integer that defines the random state.\n",
    "    seed_torch : Boolean\n",
    "      If `True` sets the random seed for pytorch tensors.\n",
    "\n",
    "  Returns:\n",
    "    Nothing.\n",
    "  \"\"\"\n",
    "  if seed is None:\n",
    "    seed = np.random.choice(2 ** 32)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  if seed_torch:\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "  print(f'Random seed {seed} has been set.')\n",
    "\n",
    "\n",
    "# In case that `DataLoader` is used\n",
    "def seed_worker(worker_id):\n",
    "\n",
    "  worker_seed = torch.initial_seed() % 2**32\n",
    "  np.random.seed(worker_seed)\n",
    "  random.seed(worker_seed)\n",
    "\n",
    "\n",
    "def train_test_classification(net, criterion, optimizer, train_loader,\n",
    "                              test_loader, num_epochs=1, verbose=True,\n",
    "                              training_plot=False):\n",
    "  \"\"\"\n",
    "  Accumulate training loss/Evaluate performance\n",
    "\n",
    "  Args:\n",
    "    net: Instance of Net class\n",
    "      Describes the model with ReLU activation, batch size 128\n",
    "    criterion: torch.nn type\n",
    "      Criterion combines LogSoftmax and NLLLoss in one single class.\n",
    "    optimizer: torch.optim type\n",
    "      Implements Adam algorithm.\n",
    "    train_loader: torch.utils.data type\n",
    "      Combines the train dataset and sampler, and provides an iterable over the given dataset.\n",
    "    test_loader: torch.utils.data type\n",
    "      Combines the test dataset and sampler, and provides an iterable over the given dataset.\n",
    "    num_epochs: int\n",
    "      Number of epochs [default: 1]\n",
    "    verbose: boolean\n",
    "      If True, print statistics\n",
    "    training_plot=False\n",
    "      If True, display training plot\n",
    "\n",
    "  Returns:\n",
    "    Nothing\n",
    "  \"\"\"\n",
    "  net.train()\n",
    "  train_losses = []\n",
    "  for epoch in tqdm(range(num_epochs)):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "      # Get the inputs; data is a list of [inputs, labels]\n",
    "      inputs, labels = data\n",
    "      inputs = inputs.float()\n",
    "      labels = labels.long()\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      outputs = net(inputs)\n",
    "\n",
    "      loss = criterion(outputs, labels)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      if verbose:\n",
    "        train_losses += [loss.item()]\n",
    "\n",
    "  net.eval()\n",
    "\n",
    "  def test(data_loader):\n",
    "    \"\"\"\n",
    "    Function to gauge network performance\n",
    "\n",
    "    Args:\n",
    "      data_loader: torch.utils.data type\n",
    "        Combines the test dataset and sampler, and provides an iterable over the given dataset.\n",
    "\n",
    "    Returns:\n",
    "      acc: float\n",
    "        Performance of the network\n",
    "      total: int\n",
    "        Number of datapoints in the dataloader\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in data_loader:\n",
    "      inputs, labels = data\n",
    "      inputs = inputs.float()\n",
    "      labels = labels.long()\n",
    "\n",
    "      outputs = net(inputs)\n",
    "      _, predicted = torch.max(outputs, 1)\n",
    "      total += labels.size(0)\n",
    "      correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    return total, acc\n",
    "\n",
    "  train_total, train_acc = test(train_loader)\n",
    "  test_total, test_acc = test(test_loader)\n",
    "\n",
    "  if verbose:\n",
    "    print(f'\\nAccuracy on the {train_total} training samples: {train_acc:0.2f}')\n",
    "    print(f'Accuracy on the {test_total} testing samples: {test_acc:0.2f}\\n')\n",
    "\n",
    "  if training_plot:\n",
    "    plt.plot(train_losses)\n",
    "    plt.xlabel('Batch')\n",
    "    plt.ylabel('Training loss')\n",
    "    plt.show()\n",
    "\n",
    "  return train_acc, test_acc\n",
    "\n",
    "\n",
    "def shuffle_and_split_data(X, y, seed):\n",
    "  \"\"\"\n",
    "  Helper function to shuffle and split data\n",
    "\n",
    "  Args:\n",
    "    X: torch.tensor\n",
    "      Input data\n",
    "    y: torch.tensor\n",
    "      Corresponding target variables\n",
    "    seed: int\n",
    "      Set seed for reproducibility\n",
    "\n",
    "  Returns:\n",
    "    X_test: torch.tensor\n",
    "      Test data [20% of X]\n",
    "    y_test: torch.tensor\n",
    "      Labels corresponding to above mentioned test data\n",
    "    X_train: torch.tensor\n",
    "      Train data [80% of X]\n",
    "    y_train: torch.tensor\n",
    "      Labels corresponding to above mentioned train data\n",
    "  \"\"\"\n",
    "  # Set seed for reproducibility\n",
    "  torch.manual_seed(seed)\n",
    "  # Number of samples\n",
    "  N = X.shape[0]\n",
    "  # Shuffle data\n",
    "  shuffled_indices = torch.randperm(N)\n",
    "  X = X[shuffled_indices]\n",
    "  y = y[shuffled_indices]\n",
    "\n",
    "  test_size = int(0.2 * N)\n",
    "  X_test = X[:test_size]\n",
    "  y_test = y[:test_size]\n",
    "  X_train = X[test_size:]\n",
    "  y_train = y[test_size:]\n",
    "\n",
    "  return X_test, y_test, X_train, y_train\n",
    "\n",
    "\n",
    "def sample_grid(M=500, x_max=2.0):\n",
    "  \"\"\"\n",
    "  Helper function to simulate sample meshgrid\n",
    "\n",
    "  Args:\n",
    "    M: int\n",
    "      Size of the constructed tensor with meshgrid\n",
    "    x_max: float\n",
    "      Defines range for the set of points\n",
    "\n",
    "  Returns:\n",
    "    X_all: torch.tensor\n",
    "      Concatenated meshgrid tensor\n",
    "  \"\"\"\n",
    "  ii, jj = torch.meshgrid(torch.linspace(-x_max, x_max,M),\n",
    "                          torch.linspace(-x_max, x_max, M),\n",
    "                          indexing='ij')\n",
    "  X_all = torch.cat([ii.unsqueeze(-1),\n",
    "                     jj.unsqueeze(-1)],\n",
    "                     dim=-1).view(-1, 2)\n",
    "  return X_all\n",
    "\n",
    "\n",
    "def plot_decision_map(X_all, y_pred, X_test, y_test,\n",
    "                      M=500, x_max=2.0, eps=1e-3):\n",
    "  \"\"\"\n",
    "  Helper function to plot decision map\n",
    "\n",
    "  Args:\n",
    "    X_all: torch.tensor\n",
    "      Concatenated meshgrid tensor\n",
    "    y_pred: torch.tensor\n",
    "      Labels predicted by the network\n",
    "    X_test: torch.tensor\n",
    "      Test data\n",
    "    y_test: torch.tensor\n",
    "      Labels of the test data\n",
    "    M: int\n",
    "      Size of the constructed tensor with meshgrid\n",
    "    x_max: float\n",
    "      Defines range for the set of points\n",
    "    eps: float\n",
    "      Decision threshold\n",
    "\n",
    "  Returns:\n",
    "    Nothing\n",
    "  \"\"\"\n",
    "  decision_map = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "  for i in range(len(X_test)):\n",
    "    indeces = (X_all[:, 0] - X_test[i, 0])**2 + (X_all[:, 1] - X_test[i, 1])**2 < eps\n",
    "    decision_map[indeces] = (K + y_test[i]).long()\n",
    "\n",
    "  decision_map = decision_map.view(M, M).cpu()\n",
    "  plt.imshow(decision_map, extent=[-x_max, x_max, -x_max, x_max], cmap='jet')\n",
    "  plt.axis('off')\n",
    "  plt.plot()\n",
    "\n",
    "\n",
    "def plot_function_apx(x_vals, relu_activations, predicted_output):\n",
    "    \"\"\"\n",
    "    Visualizes ReLU activations and the resulting function approximation.\n",
    "\n",
    "    Args:\n",
    "      x_vals: torch.tensor\n",
    "        Input x-axis data points.\n",
    "      relu_activations: torch.tensor\n",
    "        Calculated ReLU activations along x-axis for each ReLU unit.\n",
    "      predicted_output: torch.tensor\n",
    "        Estimated output labels or function approximations (weighted sum of ReLUs).\n",
    "\n",
    "    Returns:\n",
    "      None\n",
    "    \"\"\"\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(8, 6))\n",
    "\n",
    "    ## Plot ReLU activations\n",
    "    axes[0].plot(x_vals, relu_activations.T)\n",
    "    axes[0].set_xlabel('x-values', fontsize=12)\n",
    "    axes[0].set_ylabel('Activation Levels', fontsize=12)\n",
    "    axes[0].set_title('ReLU Activations (Basis Functions)', fontsize=14)\n",
    "    relu_labels = [f\"ReLU {i + 1}\" for i in range(relu_activations.shape[0])]\n",
    "    axes[0].legend(relu_labels, ncol=2)\n",
    "\n",
    "    ## Plot the function approximation and the ground truth\n",
    "    axes[1].plot(x_vals, torch.sin(x_vals), label='Ground Truth (sin(x))', color='g', linewidth=2)\n",
    "    axes[1].plot(x_vals, predicted_output, label='Predicted Output', linestyle='--', color='r')\n",
    "    axes[1].set_xlabel('x-values', fontsize=12)\n",
    "    axes[1].set_ylabel('y(x)', fontsize=12)\n",
    "    axes[1].set_title('Function Approximation vs Ground Truth', fontsize=14)\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.tight_layout(pad=2)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_images(image, num_row=2, num_col=5):\n",
    "    # plot images\n",
    "    image_size = int(np.sqrt(image.shape[-1]))\n",
    "    image = np.reshape(image, (image.shape[0], image_size, image_size))\n",
    "    fig, axes = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n",
    "    for i in range(num_row*num_col):\n",
    "        ax = axes[i//num_col, i%num_col]\n",
    "        ax.imshow(image[i], cmap='gray', vmin=0, vmax=1)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "SEED = 2024\n",
    "# Call `seed_setter` to ensure reproducibility.\n",
    "seed_setter(seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ko8kskcC9PVC"
   },
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Psmj-hddxrHV",
    "ExecuteTime": {
     "end_time": "2024-12-06T18:58:23.309244600Z",
     "start_time": "2024-12-06T18:58:17.936937Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "mnist_data = fetch_openml(\"mnist_784\")\n",
    "x = mnist_data[\"data\"].astype('float').to_numpy()\n",
    "y = mnist_data[\"target\"].astype('int')\n",
    "\n",
    "# Normalize\n",
    "x /= 255.0\n",
    "\n",
    "# One-hot encode labels\n",
    "num_labels = len(np.unique(y))\n",
    "y_new = to_categorical(y, num_labels)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# In this section, split the data into training and test datasets, using 60,000 samples for training and the remaining samples for testing.\n",
    "num_samples = 60_000\n",
    "x_train, x_test, y_train, y_test = train_test_split( x, y_new,\n",
    "                                                    train_size=num_samples,\n",
    "                                                    random_state=SEED)\n",
    "# ---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "id": "pG5s84eyyeh8",
    "outputId": "8126a8c2-4586-4ceb-9be9-a9c7fd46efd3",
    "ExecuteTime": {
     "end_time": "2024-12-06T18:58:24.462494500Z",
     "start_time": "2024-12-06T18:58:23.377528900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: (60000, 784) (60000, 10)\n",
      "Test data: (10000, 784) (10000, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 750x400 with 10 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Training data: {} {}\".format(x_train.shape, y_train.shape))\n",
    "print(\"Test data: {} {}\".format(x_test.shape, y_test.shape))\n",
    "show_images(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0yB4KcT9ffj"
   },
   "source": [
    "# Activation Functions & Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFGJmu06sAAh"
   },
   "source": [
    "There are many activation functions which some of them listed below. In this section you should implement them.\n",
    "\n",
    "1. Sigmoid:\n",
    "$$\n",
    "\\operatorname{sigmoid}(x) = \\frac{1}{1 + \\exp(-x)}\n",
    "$$\n",
    "\n",
    "2. Softmax: $$\\operatorname{softmax}(\\mathbf X)_{ij} = \\frac{\\exp(\\mathbf X_{ij})}{\\sum_k \\exp \\mathbf X_{ik})}.$$\n",
    "\n",
    "\n",
    "3. Tanh (Hyperbolic Tangent):\n",
    "$$\n",
    "\\operatorname{tanh}(x) = \\frac{\\sinh(x)}{\\cosh(x)} = \\frac{\\exp(x) - \\exp(-x)}{\\exp(x) + \\exp(-x)}\n",
    "$$\n",
    "\n",
    "4. ReLU: $$\\operatorname{ReLU}(x) = \\max(0, x)$$\n",
    "\n",
    "5. Leaky ReLU:\n",
    "$$\n",
    "\\operatorname{LeakyReLU}(x) =\n",
    "\\begin{cases}\n",
    "x & \\text{if } x \\geq 0 \\\\\n",
    "\\alpha x & \\text{if } x < 0\n",
    "\\end{cases}\n",
    "$$\n",
    "where \\( $\\alpha$ \\) is a small constant (e.g., 0.01).\n",
    "\n",
    "6. ELU (Exponential Linear Unit):\n",
    "$$\n",
    "\\operatorname{ELU}(x) =\n",
    "\\begin{cases}\n",
    "x & \\text{if } x > 0 \\\\\n",
    "\\alpha (\\exp(x) - 1) & \\text{if } x \\leq 0\n",
    "\\end{cases}\n",
    "$$\n",
    "where ($\\alpha$) is a positive constant.\n",
    "\n",
    "7. SELU (Scaled Exponential Linear Unit):\n",
    "$$\n",
    "\\operatorname{SELU}(x) =\n",
    "\\lambda\n",
    "\\begin{cases}\n",
    "x & \\text{if } x > 0 \\\\\n",
    "\\alpha (\\exp(x) - 1) & \\text{if } x \\leq 0\n",
    "\\end{cases}\n",
    "$$\n",
    "where \\( $\\lambda$ \\) and \\( $\\alpha$ \\) are predefined constants, typically \\( $\\lambda \\approx 1.0507$ \\) and \\( $\\alpha \\approx 1.67326$ \\).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "------\n",
    "There are several optimizer algorithms for optimizing the neural network over epochs. You should implement some of those mentioned in this section:\n",
    "\n",
    "***Stochastic Gradient Descent (SGD)***\n",
    "\n",
    "SGD is the basic form of gradient descent, where each weight (\\( w \\)) and bias (\\( b \\)) parameter is updated in the opposite direction of its gradient.\n",
    "\n",
    "**Update Rule:**\n",
    "$$\n",
    "w^{(t+1)} = w^{(t)} - \\eta \\cdot \\nabla_w L(w^{(t)}, b^{(t)})\n",
    "$$\n",
    "$$\n",
    "b^{(t+1)} = b^{(t)} - \\eta \\cdot \\nabla_b L(w^{(t)}, b^{(t)})\n",
    "$$\n",
    "\n",
    "- \\( w \\): Weight parameters\n",
    "- \\( b \\): Bias parameters\n",
    "- \\( $\\eta$ \\): Learning rate\n",
    "- \\( $\\nabla_w L(w, b)$ \\): Gradient of the loss with respect to \\( w \\)\n",
    "- \\( $\\nabla_b L(w, b)$ \\): Gradient of the loss with respect to \\( b \\)\n",
    "\n",
    "<br><br>\n",
    "\n",
    "***Momentum Optimizer***\n",
    "\n",
    "Momentum optimizer smooths parameter updates by adding a velocity term to accumulate past gradients.\n",
    "\n",
    "**Update Rule:**\n",
    "1. **Velocity Update for Weights and Biases:**\n",
    "   $$\n",
    "   v_w^{(t+1)} = \\beta \\cdot v_w^{(t)} + (1 - \\beta) \\cdot \\nabla_w L(w^{(t)}, b^{(t)})\n",
    "   $$\n",
    "   $$\n",
    "   v_b^{(t+1)} = \\beta \\cdot v_b^{(t)} + (1 - \\beta) \\cdot \\nabla_b L(w^{(t)}, b^{(t)})\n",
    "   $$\n",
    "\n",
    "2. **Parameter Update:**\n",
    "   $$\n",
    "   w^{(t+1)} = w^{(t)} - \\eta \\cdot v_w^{(t+1)}\n",
    "   $$\n",
    "   $$\n",
    "   b^{(t+1)} = b^{(t)} - \\eta \\cdot v_b^{(t+1)}\n",
    "   $$\n",
    "\n",
    "- \\( $v_w$ \\): Velocity term for weights\n",
    "- \\( $v_b$ \\): Velocity term for biases\n",
    "- \\( $\\beta$ \\): Momentum term, typically set to 0.9\n",
    "\n",
    "<br><br>\n",
    "\n",
    "***Adam Optimizer***\n",
    "\n",
    "Adam combines momentum and adaptive learning rates, using both first (momentum) and second (RMSprop) moment estimates.\n",
    "\n",
    "**Update Rule:**\n",
    "1. **Compute biased first and second moment estimates:**\n",
    "   $$\n",
    "   m_w^{(t+1)} = \\beta_1 \\cdot m_w^{(t)} + (1 - \\beta_1) \\cdot \\nabla_w L(w^{(t)}, b^{(t)})\n",
    "   $$\n",
    "   $$\n",
    "   m_b^{(t+1)} = \\beta_1 \\cdot m_b^{(t)} + (1 - \\beta_1) \\cdot \\nabla_b L(w^{(t)}, b^{(t)})\n",
    "   $$\n",
    "   $$\n",
    "   v_w^{(t+1)} = \\beta_2 \\cdot v_w^{(t)} + (1 - \\beta_2) \\cdot \\left( \\nabla_w L(w^{(t)}, b^{(t)}) \\right)^2\n",
    "   $$\n",
    "   $$\n",
    "   v_b^{(t+1)} = \\beta_2 \\cdot v_b^{(t)} + (1 - \\beta_2) \\cdot \\left( \\nabla_b L(w^{(t)}, b^{(t)}) \\right)^2\n",
    "   $$\n",
    "\n",
    "2. **Compute bias-corrected estimates:**\n",
    "   $$\n",
    "   \\hat{m}_w^{(t+1)} = \\frac{m_w^{(t+1)}}{1 - \\beta_1^{t+1}}, \\quad \\hat{m}_b^{(t+1)} = \\frac{m_b^{(t+1)}}{1 - \\beta_1^{t+1}}\n",
    "   $$\n",
    "   $$\n",
    "   \\hat{v}_w^{(t+1)} = \\frac{v_w^{(t+1)}}{1 - \\beta_2^{t+1}}, \\quad \\hat{v}_b^{(t+1)} = \\frac{v_b^{(t+1)}}{1 - \\beta_2^{t+1}}\n",
    "   $$\n",
    "\n",
    "3. **Parameter Update:**\n",
    "   $$\n",
    "   w^{(t+1)} = w^{(t)} - \\eta \\cdot \\frac{\\hat{m}_w^{(t+1)}}{\\sqrt{\\hat{v}_w^{(t+1)}} + \\epsilon}\n",
    "   $$\n",
    "   $$\n",
    "   b^{(t+1)} = b^{(t)} - \\eta \\cdot \\frac{\\hat{m}_b^{(t+1)}}{\\sqrt{\\hat{v}_b^{(t+1)}} + \\epsilon}\n",
    "   $$\n",
    "\n",
    "- \\( $m_w$ \\), \\( $m_b$ \\): First moment estimates (mean of gradients) for weights and biases\n",
    "- \\( $v_w$ \\), \\( $v_b$ \\): Second moment estimates (uncentered variance of gradients) for weights and biases\n",
    "- \\( $\\beta_1$ \\): Decay rate for first moment, typically 0.9\n",
    "- \\( $\\beta_2$ \\): Decay rate for second moment, typically 0.999\n",
    "- \\( $\\epsilon$ \\): Small constant for numerical stability (e.g., \\(10^{-8}\\))"
   ],
   "metadata": {
    "id": "I_cQudDfrG7D"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "83ucvivl9vec"
   },
   "source": [
    "# MLP from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "FGfYG_DfJL9b",
    "ExecuteTime": {
     "end_time": "2024-12-06T18:58:24.502594900Z",
     "start_time": "2024-12-06T18:58:24.462494500Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLP():\n",
    "    def __init__(self, sizes, activation='sigmoid'):\n",
    "        self.sizes = sizes\n",
    "        self.num_layers = len(sizes) - 1  # number of layers excluding input\n",
    "        self.activation_name = activation\n",
    "\n",
    "        # Choose activation function\n",
    "        if activation == 'relu':\n",
    "            self.activation = self.relu\n",
    "        elif activation == 'sigmoid':\n",
    "            self.activation = self.sigmoid\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = self.tanh\n",
    "        # ---------------------------------------------------------------------\n",
    "\n",
    "        elif activation == 'softmax':\n",
    "            self.activation = self.softmax\n",
    "        elif activation == 'leaky_relu':\n",
    "            self.activation = self.leaky_relu\n",
    "        elif activation == 'elu':\n",
    "            self.activation = self.elu\n",
    "        elif activation == 'selu':\n",
    "            self.activation = self.selu\n",
    "\n",
    "        # ---------------------------------------------------------------------\n",
    "        else:\n",
    "            raise ValueError(\"This activation function is currently not supported!\")\n",
    "\n",
    "        # Save all weights\n",
    "        self.params = self.initialize()\n",
    "        # print(\"params:\")\n",
    "        # for p in self.params:\n",
    "        #   print(f'{p}: {self.params[p].shape}')\n",
    "        # Save all intermediate values, i.e. activations\n",
    "        self.cache = {}\n",
    "\n",
    "    # Activation functions remain the same as defined in your original code\n",
    "    def relu(self, x, derivative=False):\n",
    "        '''\n",
    "            Forward path:\n",
    "            relu(x) = max(0, x)\n",
    "            In other word,\n",
    "            relu(x) = 0, if x < 0\n",
    "                    = x, if x >= 0\n",
    "\n",
    "            Backward path:\n",
    "            ∇relu(x) = 0, if x < 0\n",
    "                     = 1, if x >=0\n",
    "        '''\n",
    "        # ---------------------------------------------------------------------\n",
    "        if derivative:\n",
    "            return np.where(x>0, 1, 0)\n",
    "        else:\n",
    "            return np.maximum(x, 0)\n",
    "        # ---------------------------------------------------------------------\n",
    "\n",
    "    def tanh(self, x, derivative=False):\n",
    "        '''\n",
    "            Forward path:\n",
    "            tanh(x) = (exp(x) - exp(-x)) / (exp(x) + exp(-x))\n",
    "\n",
    "            Backward path:\n",
    "            ∇tanh(x) = 1 - tanh(x)^2\n",
    "        '''\n",
    "        # ---------------------------------------------------------------------\n",
    "        if derivative:\n",
    "            return 1 - self.tanh(x, derivative=False) ** 2\n",
    "        else:\n",
    "            pos = np.exp(x)\n",
    "            neg = np.exp(-x)\n",
    "            return (pos - neg) / (pos + neg)\n",
    "        # ---------------------------------------------------------------------\n",
    "\n",
    "    def sigmoid(self, x, derivative=False):\n",
    "        '''\n",
    "            Forward path:\n",
    "            σ(x) = 1 / 1+exp(-z)\n",
    "\n",
    "            Backward path:\n",
    "            ∇σ(x) = exp(-z) / (1+exp(-z))^2\n",
    "        '''\n",
    "        # ---------------------------------------------------------------------\n",
    "        if derivative:\n",
    "            return np.exp(-x) / (1 + np.exp(-x)) ** 2\n",
    "        else:\n",
    "            return 1 / (1 + np.exp(-x))\n",
    "        # ---------------------------------------------------------------------\n",
    "\n",
    "    def softmax(self, x):\n",
    "        '''\n",
    "            softmax(x) = exp(x) / ∑exp(x)\n",
    "        '''\n",
    "        # Numerically stable with large exponentials\n",
    "        # ---------------------------------------------------------------------\n",
    "        e_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return e_x / np.sum(e_x, axis=1, keepdims=True)\n",
    "        # ---------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    def leaky_relu(self, x, alpha=0.01, derivative=False):\n",
    "        '''\n",
    "            Forward path:\n",
    "            leaky_relu(x) = x if x >= 0 else αx\n",
    "\n",
    "            Backward path:\n",
    "            ∇leaky_relu(x) = 1 if x >= 0 else α\n",
    "        '''\n",
    "        # ---------------------------------------------------------------------\n",
    "        if derivative:\n",
    "            return np.where(x>0, 1, alpha)\n",
    "        else:\n",
    "            return np.maximum(x, alpha * x)\n",
    "        # ---------------------------------------------------------------------\n",
    "\n",
    "    def elu(self, x, alpha=1.0, derivative=False):\n",
    "        '''\n",
    "            Forward path:\n",
    "            elu(x) = x if x > 0 else α(exp(x) - 1)\n",
    "\n",
    "            Backward path:\n",
    "            ∇elu(x) = 1 if x > 0 else α * exp(x)\n",
    "        '''\n",
    "        # ---------------------------------------------------------------------\n",
    "        if derivative:\n",
    "            return np.where(x > 0, 1, alpha*np.exp(x))\n",
    "        else:\n",
    "            return np.where(x > 0, x, alpha * (np.exp(x)-1))\n",
    "        # ---------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    def selu(self, x, lambda_=1.0507, alpha=1.67326, derivative=False):\n",
    "        '''\n",
    "            Forward path:\n",
    "            selu(x) = λ * (x if x > 0 else α * (exp(x) - 1))\n",
    "\n",
    "            Backward path:\n",
    "            ∇selu(x) = λ * (1 if x > 0 else α * exp(x))\n",
    "        '''\n",
    "        # ---------------------------------------------------------------------\n",
    "        if derivative:\n",
    "            return lambda_ * np.where(x > 0, 1, alpha*np.exp(x))\n",
    "        else:\n",
    "            return lambda_ * np.where(x > 0, x, alpha * (np.exp(x)-1))\n",
    "        # ---------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    def initialize(self):\n",
    "        params = {}\n",
    "        for i in range(1, self.num_layers + 1):\n",
    "            input_layer = self.sizes[i - 1]\n",
    "            output_layer = self.sizes[i]\n",
    "            params[f\"W{i}\"] = np.random.randn(output_layer, input_layer) * np.sqrt(1. / input_layer)\n",
    "            params[f\"b{i}\"] = np.zeros((output_layer, 1))\n",
    "        return params\n",
    "\n",
    "    def feed_forward(self, x):\n",
    "        self.cache[\"A0\"] = x\n",
    "        # ---------------------------------------------------------------------\n",
    "        # Perform feedforward pass through each hidden layer, applying weights, biases, and activation function\n",
    "        for i in range(1, self.num_layers + 1):\n",
    "\n",
    "            W = self.params[f\"W{i}\"]\n",
    "            b = self.params[f\"b{i}\"]\n",
    "\n",
    "            Z = np.dot(self.cache[f'A{i-1}'], W.T) + b.T\n",
    "            self.cache[f'Z{i}'] = Z\n",
    "\n",
    "            if i == self.num_layers:\n",
    "                self.cache[f'A{i}'] = self.softmax(Z)\n",
    "            else:\n",
    "                self.cache[f'A{i}'] = self.activation(Z)\n",
    "                # print(self.cache[f'A{i}'].shape)\n",
    "        # ---------------------------------------------------------------------\n",
    "\n",
    "        return self.cache[f\"A{self.num_layers}\"]\n",
    "\n",
    "    def back_propagate(self, y, output):\n",
    "        current_batch_size = y.shape[0]\n",
    "        grads = {}\n",
    "\n",
    "        # ---------------------------------------------------------------------\n",
    "        # Backpropagate gradients through Output layer and each hidden layers\n",
    "        dA = output - y\n",
    "        for _ in range(self.num_layers, 0, -1):\n",
    "            Z = self.cache[f'Z{_}']\n",
    "            A_prev = self.cache[f'A{_-1}']\n",
    "\n",
    "            # print(\"nigga\", _, Z.shape, A_prev, dA.shape)\n",
    "            dZ = dA * self.activation(Z, derivative=True)\n",
    "            dW = np.dot(dZ.T, A_prev) / current_batch_size\n",
    "            db = np.sum(dZ, axis=0, keepdims=True).T / current_batch_size\n",
    "\n",
    "            grads[f'W{_}'] = dW\n",
    "            grads[f'b{_}'] = db\n",
    "\n",
    "            if _ > 1:\n",
    "                dA = np.dot(dZ, self.params[f\"W{_}\"])\n",
    "\n",
    "        # ---------------------------------------------------------------------\n",
    "\n",
    "        self.grads = grads\n",
    "        return self.grads\n",
    "\n",
    "\n",
    "    def cross_entropy_loss(self, y, output):\n",
    "        '''\n",
    "            L(y, ŷ) = −∑ylog(ŷ).\n",
    "        '''\n",
    "        # ---------------------------------------------------------------------\n",
    "        # Compute cross-entropy loss as the negative average log-likelihood of the correct labels\n",
    "        epsilon = 1e-10\n",
    "        l = (-1 / y.shape[0]) * np.sum(y * np.log(output + epsilon))\n",
    "        # ---------------------------------------------------------------------\n",
    "        return l\n",
    "\n",
    "    def initialize_momemtum_optimizer(self):\n",
    "        momemtum_opt = {}\n",
    "        for i in range(1, self.num_layers + 1):\n",
    "            # ---------------------------------------------------------------------\n",
    "            # Initialize zero matrices for momentum updates of weights and biases in each layer\n",
    "            momemtum_opt[f'W{i}'] = np.zeros_like(self.params[f'W{i}'])\n",
    "            momemtum_opt[f'b{i}'] = np.zeros_like(self.params[f'b{i}'])\n",
    "            # ---------------------------------------------------------------------\n",
    "        return momemtum_opt\n",
    "\n",
    "    def initialize_adam_optimizer(self):\n",
    "        adam_opt = {'m': {}, 'v': {}}\n",
    "        for i in range(1, self.num_layers + 1):\n",
    "            # -------------------------------- TODO -------------------------------------\n",
    "            # Initialize zero matrices for first and second moment estimates of weights and biases in each layer\n",
    "            adam_opt['m'][f'W{i}'] = np.zeros_like(self.params[f'W{i}'])\n",
    "            adam_opt['m'][f'b{i}'] = np.zeros_like(self.params[f'b{i}'])\n",
    "            adam_opt['v'][f'W{i}'] = np.zeros_like(self.params[f'W{i}'])\n",
    "            adam_opt['v'][f'b{i}'] = np.zeros_like(self.params[f'b{i}'])\n",
    "            # -------------------------------- TODO -------------------------------------\n",
    "        return adam_opt\n",
    "\n",
    "    def optimize(self, l_rate=0.1, beta=.9, beta1=0.9, beta2=0.999, epsilon=1e-8, t=1):\n",
    "\n",
    "        if self.optimizer == \"sgd\":\n",
    "            for key in self.params:\n",
    "                # ---------------------------------------------------------------------\n",
    "                # Update rule for SGD\n",
    "                self.params[key] -= l_rate * self.grads[key]\n",
    "                # ---------------------------------------------------------------------\n",
    "        elif self.optimizer == \"momentum\":\n",
    "            for key in self.params:\n",
    "                # ---------------------------------------------------------------------\n",
    "                # Update rule for Momentum\n",
    "                self.momemtum_opt[key] = beta * self.momemtum_opt[key] + (1-beta) * self.grads[key]\n",
    "                self.params[key] -= l_rate * self.momemtum_opt[key]\n",
    "                # ---------------------------------------------------------------------\n",
    "        elif self.optimizer == \"adam\":\n",
    "            for key in self.params:\n",
    "                # ---------------------------------------------------------------------\n",
    "                # Update rule for Adam\n",
    "                self.adam_opt['m'][key] = beta1 * self.adam_opt['m'][key] + (1-beta1) * self.grads[key]\n",
    "                self.adam_opt['v'][key] = beta2 * self.adam_opt['v'][key] + (1-beta2) * (self.grads[key]**2)\n",
    "                m_hat = self.adam_opt['m'][key] / (1 - beta1**t)\n",
    "                v_hat = self.adam_opt['v'][key] / (1 - beta2**t)\n",
    "                self.params[key] -= l_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n",
    "                # ---------------------------------------------------------------------\n",
    "        else:\n",
    "            raise ValueError(\"This optimizer is currently not supported!\")\n",
    "\n",
    "    # Accuracy, loss, and training methods remain the same as defined in your original code\n",
    "\n",
    "\n",
    "    def accuracy(self, y, output):\n",
    "        # ---------------------------------------------------------------------\n",
    "        # Calculate accuracy by comparing the pred and truth matrices\n",
    "        pred = np.argmax(output, axis=1)\n",
    "        label = np.argmax(y, axis=1)\n",
    "        return np.mean(pred == label)\n",
    "        # ---------------------------------------------------------------------\n",
    "\n",
    "    def train(self, x_train, y_train, x_val, y_val, epochs=10,\n",
    "              batch_size=64, optimizer='momentum', l_rate=0.1, beta=.9, beta1=0.9, beta2=0.999, epsilon=1e-8, t=1):\n",
    "        # Hyperparameters\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        num_batches = -(-x_train.shape[0] // self.batch_size)\n",
    "\n",
    "        # Initialize optimizer\n",
    "        self.optimizer = optimizer\n",
    "        if self.optimizer == 'momentum':\n",
    "          self.momemtum_opt = self.initialize_momemtum_optimizer()\n",
    "        elif self.optimizer == 'adam':\n",
    "          self.adam_opt = self.initialize_adam_optimizer()\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Train\n",
    "        for i in range(self.epochs):\n",
    "            # Shuffle\n",
    "            permutation = np.random.permutation(x_train.shape[0])\n",
    "            x_train_shuffled = x_train[permutation]\n",
    "            y_train_shuffled = y_train[permutation]\n",
    "\n",
    "            for j in range(num_batches):\n",
    "                # Batch\n",
    "                begin = j * self.batch_size\n",
    "                end = min(begin + self.batch_size, x_train.shape[0]-1)\n",
    "                x = x_train_shuffled[begin:end]\n",
    "                y = y_train_shuffled[begin:end]\n",
    "\n",
    "                # Forward\n",
    "                output = self.feed_forward(x)\n",
    "                # Backprop\n",
    "                grad = self.back_propagate(y, output)\n",
    "                # Optimize\n",
    "                self.optimize(l_rate=l_rate, beta=beta, beta1=beta1, beta2=beta2, epsilon=epsilon, t=t)\n",
    "\n",
    "            # Evaluate performance\n",
    "            # Training data\n",
    "            output = self.feed_forward(x_train)\n",
    "            train_acc = self.accuracy(y_train, output)\n",
    "            train_loss = self.cross_entropy_loss(y_train, output)\n",
    "            # Test data\n",
    "            output = self.feed_forward(x_val)\n",
    "            val_acc = self.accuracy(y_val, output)\n",
    "            val_loss = self.cross_entropy_loss(y_val, output)\n",
    "            print(f'Epoch {i+1}: {time.time()-start_time:.2f}s, train acc={train_acc:.2f}, train loss={train_loss:.2f}, '\n",
    "                      f'validation acc={val_acc:.2f}, validation loss={val_loss:.2f}')\n",
    "\n",
    "    def evaluate(self, x_test, y_test):\n",
    "        # Test data\n",
    "        output = self.feed_forward(x_test)\n",
    "        test_acc = self.accuracy(y_test, output)\n",
    "        test_loss = self.cross_entropy_loss(y_test, output)\n",
    "        print(f'\\nTest acc={test_acc:.2f}, Test loss={test_loss:.2f}')\n",
    "        return test_acc, test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Please run experiments with different combinations of optimizers (SGD, Momentum, and Adam) and activation functions (ReLU, Sigmoid, Tanh, Leaky ReLU, SELU, and ELU) over 20 epochs each. Consider networks with three layers (without input layer) whose number of neurons is 128, 64 and 10 respectively. Also consider two learning rates 0.01 and 0.001.\n",
    "\n",
    "\n",
    "After testing all combinations, report which combination of optimizer, activation function, and learning rate performs best.\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "dnSR8IkArgeT"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Run your experiments here ...\n",
    "\n",
    "def print_header(act, opt, lr):\n",
    "    line_len = 110\n",
    "    output_header = f'Activation: {act}, Optimizer: {opt}, Learning Rate: {lr}'\n",
    "    print(\"\\n\")\n",
    "    print('+', '-' * line_len, '+')\n",
    "    print('|', ' ' * line_len, '|')\n",
    "    print(f'| {\" \" * ((line_len - len(output_header) + 1) // 2)}{output_header}{\" \" * ((line_len - len(output_header)) // 2)} |')\n",
    "    print('|', ' ' * line_len, '|')\n",
    "    print('+', '-' * line_len, '+')\n",
    "\n",
    "\n",
    "# Hyper parameters\n",
    "n_epochs = 20\n",
    "l_rate1, l_rate2 = 0.01, 0.001\n",
    "batch_size = 64\n",
    "sizes = [784, 128, 64, 10]\n",
    "activation_functions = ['relu', 'sigmoid', 'tanh', 'leaky_relu', 'selu', 'elu']\n",
    "optimizers = ['sgd', 'momentum', 'adam']\n",
    "\n",
    "best_model = None\n",
    "best_acc, best_loss = 0, float('inf')\n",
    "for activation in activation_functions:\n",
    "    for optimizer in optimizers:\n",
    "        for l_rate in [l_rate1, l_rate2]:\n",
    "            print_header(activation, optimizer, l_rate)\n",
    "            mlp = MLP(sizes, activation=activation)\n",
    "            mlp.train(x_train, y_train, x_test, y_test, epochs=n_epochs, batch_size=batch_size, optimizer=optimizer, l_rate=l_rate)\n",
    "            acc, loss = mlp.evaluate(x_test, y_test)\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_loss = loss\n",
    "                best_model = (activation, optimizer, l_rate)\n",
    "\n",
    "\n",
    "\n",
    "print(f'\\n\\nBest model: {best_model}, Accuracy: {best_acc}, Loss: {best_loss}')\n"
   ],
   "metadata": {
    "id": "4zAksBBzrigw",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "2b542652-013e-4a2a-c886-b16cef0904ab",
    "ExecuteTime": {
     "end_time": "2024-12-06T19:35:48.751050300Z",
     "start_time": "2024-12-06T18:58:24.497595700Z"
    }
   },
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "|                                                                                                                |\n",
      "|                              Activation: relu, Optimizer: sgd, Learning Rate: 0.01                             |\n",
      "|                                                                                                                |\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "Epoch 1: 2.18s, train acc=0.69, train loss=1.10, validation acc=0.68, validation loss=1.12\n",
      "Epoch 2: 3.95s, train acc=0.72, train loss=0.87, validation acc=0.71, validation loss=0.89\n",
      "Epoch 3: 5.57s, train acc=0.74, train loss=0.77, validation acc=0.73, validation loss=0.80\n",
      "Epoch 4: 7.40s, train acc=0.75, train loss=0.70, validation acc=0.74, validation loss=0.74\n",
      "Epoch 5: 9.04s, train acc=0.76, train loss=0.68, validation acc=0.75, validation loss=0.72\n",
      "Epoch 6: 10.73s, train acc=0.76, train loss=0.65, validation acc=0.75, validation loss=0.69\n",
      "Epoch 7: 12.32s, train acc=0.77, train loss=0.64, validation acc=0.76, validation loss=0.67\n",
      "Epoch 8: 14.23s, train acc=0.77, train loss=0.61, validation acc=0.76, validation loss=0.65\n",
      "Epoch 9: 15.75s, train acc=0.78, train loss=0.59, validation acc=0.77, validation loss=0.62\n",
      "Epoch 10: 17.56s, train acc=0.79, train loss=0.56, validation acc=0.78, validation loss=0.60\n",
      "Epoch 11: 19.18s, train acc=0.78, train loss=0.57, validation acc=0.77, validation loss=0.61\n",
      "Epoch 12: 20.95s, train acc=0.79, train loss=0.55, validation acc=0.78, validation loss=0.60\n",
      "Epoch 13: 22.62s, train acc=0.79, train loss=0.53, validation acc=0.78, validation loss=0.57\n",
      "Epoch 14: 24.32s, train acc=0.80, train loss=0.52, validation acc=0.78, validation loss=0.56\n",
      "Epoch 15: 25.86s, train acc=0.80, train loss=0.51, validation acc=0.79, validation loss=0.56\n",
      "Epoch 16: 27.52s, train acc=0.80, train loss=0.51, validation acc=0.78, validation loss=0.55\n",
      "Epoch 17: 29.05s, train acc=0.80, train loss=0.50, validation acc=0.79, validation loss=0.54\n",
      "Epoch 18: 30.72s, train acc=0.80, train loss=0.50, validation acc=0.79, validation loss=0.54\n",
      "Epoch 19: 32.41s, train acc=0.81, train loss=0.48, validation acc=0.79, validation loss=0.52\n",
      "Epoch 20: 34.15s, train acc=0.81, train loss=0.47, validation acc=0.79, validation loss=0.52\n",
      "\n",
      "Test acc=0.79, Test loss=0.52\n",
      "\n",
      "\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "|                                                                                                                |\n",
      "|                             Activation: relu, Optimizer: sgd, Learning Rate: 0.001                             |\n",
      "|                                                                                                                |\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "Epoch 1: 1.83s, train acc=0.35, train loss=2.17, validation acc=0.34, validation loss=2.17\n",
      "Epoch 2: 3.66s, train acc=0.48, train loss=1.94, validation acc=0.47, validation loss=1.95\n",
      "Epoch 3: 5.57s, train acc=0.62, train loss=1.66, validation acc=0.61, validation loss=1.68\n",
      "Epoch 4: 7.35s, train acc=0.69, train loss=1.41, validation acc=0.68, validation loss=1.44\n",
      "Epoch 5: 8.73s, train acc=0.73, train loss=1.24, validation acc=0.71, validation loss=1.27\n",
      "Epoch 6: 10.27s, train acc=0.76, train loss=1.12, validation acc=0.74, validation loss=1.16\n",
      "Epoch 7: 11.83s, train acc=0.77, train loss=1.04, validation acc=0.76, validation loss=1.08\n",
      "Epoch 8: 13.68s, train acc=0.78, train loss=0.98, validation acc=0.77, validation loss=1.02\n",
      "Epoch 9: 15.33s, train acc=0.79, train loss=0.93, validation acc=0.78, validation loss=0.98\n",
      "Epoch 10: 17.18s, train acc=0.80, train loss=0.89, validation acc=0.79, validation loss=0.94\n",
      "Epoch 11: 18.91s, train acc=0.80, train loss=0.87, validation acc=0.79, validation loss=0.91\n",
      "Epoch 12: 20.76s, train acc=0.81, train loss=0.84, validation acc=0.79, validation loss=0.89\n",
      "Epoch 13: 22.54s, train acc=0.81, train loss=0.82, validation acc=0.80, validation loss=0.87\n",
      "Epoch 14: 24.36s, train acc=0.81, train loss=0.80, validation acc=0.80, validation loss=0.85\n",
      "Epoch 15: 26.12s, train acc=0.81, train loss=0.79, validation acc=0.80, validation loss=0.84\n",
      "Epoch 16: 27.99s, train acc=0.82, train loss=0.78, validation acc=0.80, validation loss=0.83\n",
      "Epoch 17: 29.66s, train acc=0.82, train loss=0.76, validation acc=0.80, validation loss=0.81\n",
      "Epoch 18: 31.42s, train acc=0.82, train loss=0.75, validation acc=0.81, validation loss=0.81\n",
      "Epoch 19: 33.01s, train acc=0.82, train loss=0.74, validation acc=0.81, validation loss=0.80\n",
      "Epoch 20: 34.84s, train acc=0.82, train loss=0.74, validation acc=0.81, validation loss=0.79\n",
      "\n",
      "Test acc=0.81, Test loss=0.79\n",
      "\n",
      "\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "|                                                                                                                |\n",
      "|                           Activation: relu, Optimizer: momentum, Learning Rate: 0.01                           |\n",
      "|                                                                                                                |\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "Epoch 1: 2.44s, train acc=0.78, train loss=0.84, validation acc=0.77, validation loss=0.88\n",
      "Epoch 2: 4.78s, train acc=0.81, train loss=0.62, validation acc=0.80, validation loss=0.67\n",
      "Epoch 3: 7.20s, train acc=0.83, train loss=0.53, validation acc=0.82, validation loss=0.57\n",
      "Epoch 4: 9.40s, train acc=0.84, train loss=0.48, validation acc=0.83, validation loss=0.53\n",
      "Epoch 5: 11.62s, train acc=0.86, train loss=0.44, validation acc=0.84, validation loss=0.49\n",
      "Epoch 6: 13.63s, train acc=0.86, train loss=0.42, validation acc=0.85, validation loss=0.47\n",
      "Epoch 7: 16.02s, train acc=0.88, train loss=0.39, validation acc=0.86, validation loss=0.44\n",
      "Epoch 8: 18.05s, train acc=0.88, train loss=0.37, validation acc=0.87, validation loss=0.42\n",
      "Epoch 9: 20.42s, train acc=0.88, train loss=0.37, validation acc=0.86, validation loss=0.42\n",
      "Epoch 10: 22.60s, train acc=0.89, train loss=0.34, validation acc=0.88, validation loss=0.40\n",
      "Epoch 11: 25.02s, train acc=0.89, train loss=0.35, validation acc=0.87, validation loss=0.40\n",
      "Epoch 12: 27.71s, train acc=0.90, train loss=0.33, validation acc=0.88, validation loss=0.39\n",
      "Epoch 13: 29.99s, train acc=0.90, train loss=0.32, validation acc=0.89, validation loss=0.37\n",
      "Epoch 14: 32.33s, train acc=0.91, train loss=0.30, validation acc=0.89, validation loss=0.36\n",
      "Epoch 15: 34.86s, train acc=0.91, train loss=0.30, validation acc=0.89, validation loss=0.36\n",
      "Epoch 16: 37.33s, train acc=0.91, train loss=0.29, validation acc=0.89, validation loss=0.35\n",
      "Epoch 17: 39.78s, train acc=0.91, train loss=0.29, validation acc=0.89, validation loss=0.35\n",
      "Epoch 18: 42.31s, train acc=0.92, train loss=0.28, validation acc=0.90, validation loss=0.33\n",
      "Epoch 19: 44.86s, train acc=0.92, train loss=0.27, validation acc=0.90, validation loss=0.33\n",
      "Epoch 20: 47.39s, train acc=0.92, train loss=0.27, validation acc=0.90, validation loss=0.33\n",
      "\n",
      "Test acc=0.90, Test loss=0.33\n",
      "\n",
      "\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "|                                                                                                                |\n",
      "|                           Activation: relu, Optimizer: momentum, Learning Rate: 0.001                          |\n",
      "|                                                                                                                |\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "Epoch 1: 2.28s, train acc=0.43, train loss=2.17, validation acc=0.42, validation loss=2.17\n",
      "Epoch 2: 4.73s, train acc=0.64, train loss=1.89, validation acc=0.63, validation loss=1.89\n",
      "Epoch 3: 7.15s, train acc=0.72, train loss=1.50, validation acc=0.70, validation loss=1.51\n",
      "Epoch 4: 9.54s, train acc=0.78, train loss=1.14, validation acc=0.76, validation loss=1.16\n",
      "Epoch 5: 11.86s, train acc=0.81, train loss=0.90, validation acc=0.80, validation loss=0.91\n",
      "Epoch 6: 14.17s, train acc=0.83, train loss=0.74, validation acc=0.83, validation loss=0.76\n",
      "Epoch 7: 16.39s, train acc=0.84, train loss=0.65, validation acc=0.84, validation loss=0.67\n",
      "Epoch 8: 18.88s, train acc=0.85, train loss=0.58, validation acc=0.85, validation loss=0.61\n",
      "Epoch 9: 21.25s, train acc=0.86, train loss=0.54, validation acc=0.86, validation loss=0.56\n",
      "Epoch 10: 23.69s, train acc=0.87, train loss=0.50, validation acc=0.86, validation loss=0.53\n",
      "Epoch 11: 26.23s, train acc=0.88, train loss=0.47, validation acc=0.87, validation loss=0.50\n",
      "Epoch 12: 28.76s, train acc=0.88, train loss=0.45, validation acc=0.87, validation loss=0.48\n",
      "Epoch 13: 31.23s, train acc=0.88, train loss=0.43, validation acc=0.88, validation loss=0.46\n",
      "Epoch 14: 33.68s, train acc=0.89, train loss=0.42, validation acc=0.88, validation loss=0.45\n",
      "Epoch 15: 36.05s, train acc=0.89, train loss=0.40, validation acc=0.88, validation loss=0.44\n",
      "Epoch 16: 38.56s, train acc=0.89, train loss=0.39, validation acc=0.88, validation loss=0.43\n",
      "Epoch 17: 41.00s, train acc=0.89, train loss=0.38, validation acc=0.89, validation loss=0.42\n",
      "Epoch 18: 43.56s, train acc=0.89, train loss=0.37, validation acc=0.89, validation loss=0.41\n",
      "Epoch 19: 46.03s, train acc=0.90, train loss=0.37, validation acc=0.89, validation loss=0.40\n",
      "Epoch 20: 48.20s, train acc=0.90, train loss=0.36, validation acc=0.89, validation loss=0.40\n",
      "\n",
      "Test acc=0.89, Test loss=0.40\n",
      "\n",
      "\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "|                                                                                                                |\n",
      "|                             Activation: relu, Optimizer: adam, Learning Rate: 0.01                             |\n",
      "|                                                                                                                |\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "Epoch 1: 3.03s, train acc=0.10, train loss=17.89, validation acc=0.11, validation loss=17.70\n",
      "Epoch 2: 6.13s, train acc=0.10, train loss=17.89, validation acc=0.11, validation loss=17.70\n",
      "Epoch 3: 9.25s, train acc=0.10, train loss=17.89, validation acc=0.11, validation loss=17.70\n",
      "Epoch 4: 12.41s, train acc=0.10, train loss=17.89, validation acc=0.11, validation loss=17.70\n",
      "Epoch 5: 15.58s, train acc=0.10, train loss=17.89, validation acc=0.11, validation loss=17.70\n",
      "Epoch 6: 18.76s, train acc=0.10, train loss=17.89, validation acc=0.11, validation loss=17.70\n",
      "Epoch 7: 21.93s, train acc=0.10, train loss=17.89, validation acc=0.11, validation loss=17.70\n",
      "Epoch 8: 27.49s, train acc=0.10, train loss=17.89, validation acc=0.11, validation loss=17.70\n",
      "Epoch 9: 33.26s, train acc=0.10, train loss=17.89, validation acc=0.11, validation loss=17.70\n",
      "Epoch 10: 39.01s, train acc=0.10, train loss=17.89, validation acc=0.11, validation loss=17.70\n",
      "Epoch 11: 44.73s, train acc=0.10, train loss=17.89, validation acc=0.11, validation loss=17.70\n",
      "Epoch 12: 50.43s, train acc=0.10, train loss=17.89, validation acc=0.11, validation loss=17.70\n",
      "Epoch 13: 56.19s, train acc=0.10, train loss=17.89, validation acc=0.11, validation loss=17.70\n",
      "Epoch 14: 61.93s, train acc=0.10, train loss=17.89, validation acc=0.11, validation loss=17.70\n",
      "Epoch 15: 67.76s, train acc=0.10, train loss=17.89, validation acc=0.11, validation loss=17.70\n",
      "Epoch 16: 73.53s, train acc=0.10, train loss=17.89, validation acc=0.11, validation loss=17.70\n",
      "Epoch 17: 79.37s, train acc=0.10, train loss=17.89, validation acc=0.11, validation loss=17.70\n",
      "Epoch 18: 85.19s, train acc=0.10, train loss=17.89, validation acc=0.11, validation loss=17.70\n",
      "Epoch 19: 90.95s, train acc=0.10, train loss=17.89, validation acc=0.11, validation loss=17.70\n",
      "Epoch 20: 96.78s, train acc=0.10, train loss=17.89, validation acc=0.11, validation loss=17.70\n",
      "\n",
      "Test acc=0.11, Test loss=17.70\n",
      "\n",
      "\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "|                                                                                                                |\n",
      "|                             Activation: relu, Optimizer: adam, Learning Rate: 0.001                            |\n",
      "|                                                                                                                |\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "Epoch 1: 3.15s, train acc=0.59, train loss=1.50, validation acc=0.57, validation loss=1.55\n",
      "Epoch 2: 6.32s, train acc=0.60, train loss=1.42, validation acc=0.58, validation loss=1.47\n",
      "Epoch 3: 9.47s, train acc=0.62, train loss=1.26, validation acc=0.60, validation loss=1.31\n",
      "Epoch 4: 12.62s, train acc=0.61, train loss=1.25, validation acc=0.60, validation loss=1.31\n",
      "Epoch 5: 15.81s, train acc=0.63, train loss=1.21, validation acc=0.61, validation loss=1.26\n",
      "Epoch 6: 18.93s, train acc=0.63, train loss=1.20, validation acc=0.61, validation loss=1.26\n",
      "Epoch 7: 22.12s, train acc=0.63, train loss=1.19, validation acc=0.61, validation loss=1.25\n",
      "Epoch 8: 25.50s, train acc=0.64, train loss=1.15, validation acc=0.62, validation loss=1.21\n",
      "Epoch 9: 28.83s, train acc=0.64, train loss=1.07, validation acc=0.62, validation loss=1.13\n",
      "Epoch 10: 32.08s, train acc=0.63, train loss=1.11, validation acc=0.62, validation loss=1.17\n",
      "Epoch 11: 35.51s, train acc=0.65, train loss=1.12, validation acc=0.63, validation loss=1.19\n",
      "Epoch 12: 38.87s, train acc=0.63, train loss=1.18, validation acc=0.62, validation loss=1.25\n",
      "Epoch 13: 42.27s, train acc=0.65, train loss=1.08, validation acc=0.63, validation loss=1.15\n",
      "Epoch 14: 45.72s, train acc=0.64, train loss=1.08, validation acc=0.63, validation loss=1.15\n",
      "Epoch 15: 49.18s, train acc=0.65, train loss=1.10, validation acc=0.63, validation loss=1.18\n",
      "Epoch 16: 52.65s, train acc=0.64, train loss=1.08, validation acc=0.63, validation loss=1.15\n",
      "Epoch 17: 56.14s, train acc=0.63, train loss=1.16, validation acc=0.62, validation loss=1.23\n",
      "Epoch 18: 59.60s, train acc=0.65, train loss=1.07, validation acc=0.63, validation loss=1.15\n",
      "Epoch 19: 63.06s, train acc=0.65, train loss=1.05, validation acc=0.63, validation loss=1.12\n",
      "Epoch 20: 66.55s, train acc=0.65, train loss=1.00, validation acc=0.64, validation loss=1.08\n",
      "\n",
      "Test acc=0.64, Test loss=1.08\n",
      "\n",
      "\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "|                                                                                                                |\n",
      "|                            Activation: sigmoid, Optimizer: sgd, Learning Rate: 0.01                            |\n",
      "|                                                                                                                |\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "Epoch 1: 2.32s, train acc=0.11, train loss=2.29, validation acc=0.11, validation loss=2.29\n",
      "Epoch 2: 4.55s, train acc=0.12, train loss=2.28, validation acc=0.11, validation loss=2.28\n",
      "Epoch 3: 7.02s, train acc=0.13, train loss=2.27, validation acc=0.12, validation loss=2.27\n",
      "Epoch 4: 9.09s, train acc=0.15, train loss=2.25, validation acc=0.15, validation loss=2.25\n",
      "Epoch 5: 11.42s, train acc=0.34, train loss=2.24, validation acc=0.34, validation loss=2.24\n",
      "Epoch 6: 13.51s, train acc=0.36, train loss=2.22, validation acc=0.36, validation loss=2.22\n",
      "Epoch 7: 15.90s, train acc=0.51, train loss=2.20, validation acc=0.50, validation loss=2.20\n",
      "Epoch 8: 17.93s, train acc=0.51, train loss=2.17, validation acc=0.50, validation loss=2.17\n",
      "Epoch 9: 20.24s, train acc=0.54, train loss=2.14, validation acc=0.53, validation loss=2.14\n",
      "Epoch 10: 22.17s, train acc=0.56, train loss=2.10, validation acc=0.55, validation loss=2.10\n",
      "Epoch 11: 24.23s, train acc=0.61, train loss=2.05, validation acc=0.60, validation loss=2.05\n",
      "Epoch 12: 26.38s, train acc=0.60, train loss=1.99, validation acc=0.59, validation loss=2.00\n",
      "Epoch 13: 28.46s, train acc=0.62, train loss=1.93, validation acc=0.61, validation loss=1.93\n",
      "Epoch 14: 30.76s, train acc=0.63, train loss=1.86, validation acc=0.61, validation loss=1.86\n",
      "Epoch 15: 32.63s, train acc=0.63, train loss=1.78, validation acc=0.62, validation loss=1.79\n",
      "Epoch 16: 35.01s, train acc=0.65, train loss=1.71, validation acc=0.63, validation loss=1.72\n",
      "Epoch 17: 36.77s, train acc=0.65, train loss=1.64, validation acc=0.64, validation loss=1.64\n",
      "Epoch 18: 39.12s, train acc=0.66, train loss=1.57, validation acc=0.65, validation loss=1.58\n",
      "Epoch 19: 40.99s, train acc=0.67, train loss=1.51, validation acc=0.67, validation loss=1.51\n",
      "Epoch 20: 43.22s, train acc=0.69, train loss=1.45, validation acc=0.68, validation loss=1.46\n",
      "\n",
      "Test acc=0.68, Test loss=1.46\n",
      "\n",
      "\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "|                                                                                                                |\n",
      "|                            Activation: sigmoid, Optimizer: sgd, Learning Rate: 0.001                           |\n",
      "|                                                                                                                |\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "Epoch 1: 2.26s, train acc=0.10, train loss=2.33, validation acc=0.10, validation loss=2.33\n",
      "Epoch 2: 4.62s, train acc=0.10, train loss=2.31, validation acc=0.10, validation loss=2.31\n",
      "Epoch 3: 6.71s, train acc=0.13, train loss=2.30, validation acc=0.13, validation loss=2.30\n",
      "Epoch 4: 8.45s, train acc=0.11, train loss=2.30, validation acc=0.11, validation loss=2.30\n",
      "Epoch 5: 10.87s, train acc=0.11, train loss=2.29, validation acc=0.11, validation loss=2.29\n",
      "Epoch 6: 12.66s, train acc=0.11, train loss=2.29, validation acc=0.11, validation loss=2.29\n",
      "Epoch 7: 15.05s, train acc=0.11, train loss=2.29, validation acc=0.11, validation loss=2.29\n",
      "Epoch 8: 16.80s, train acc=0.11, train loss=2.29, validation acc=0.11, validation loss=2.29\n",
      "Epoch 9: 19.07s, train acc=0.11, train loss=2.29, validation acc=0.11, validation loss=2.29\n",
      "Epoch 10: 21.35s, train acc=0.11, train loss=2.29, validation acc=0.11, validation loss=2.29\n",
      "Epoch 11: 23.75s, train acc=0.11, train loss=2.29, validation acc=0.11, validation loss=2.29\n",
      "Epoch 12: 25.95s, train acc=0.11, train loss=2.28, validation acc=0.11, validation loss=2.28\n",
      "Epoch 13: 28.31s, train acc=0.11, train loss=2.28, validation acc=0.11, validation loss=2.28\n",
      "Epoch 14: 30.59s, train acc=0.11, train loss=2.28, validation acc=0.11, validation loss=2.28\n",
      "Epoch 15: 32.86s, train acc=0.11, train loss=2.28, validation acc=0.11, validation loss=2.28\n",
      "Epoch 16: 35.25s, train acc=0.11, train loss=2.28, validation acc=0.11, validation loss=2.28\n",
      "Epoch 17: 37.69s, train acc=0.11, train loss=2.28, validation acc=0.11, validation loss=2.28\n",
      "Epoch 18: 39.95s, train acc=0.11, train loss=2.28, validation acc=0.11, validation loss=2.28\n",
      "Epoch 19: 42.27s, train acc=0.11, train loss=2.28, validation acc=0.11, validation loss=2.28\n",
      "Epoch 20: 44.50s, train acc=0.11, train loss=2.27, validation acc=0.11, validation loss=2.28\n",
      "\n",
      "Test acc=0.11, Test loss=2.28\n",
      "\n",
      "\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "|                                                                                                                |\n",
      "|                          Activation: sigmoid, Optimizer: momentum, Learning Rate: 0.01                         |\n",
      "|                                                                                                                |\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "Epoch 1: 2.67s, train acc=0.11, train loss=2.29, validation acc=0.11, validation loss=2.29\n",
      "Epoch 2: 5.29s, train acc=0.12, train loss=2.28, validation acc=0.11, validation loss=2.28\n",
      "Epoch 3: 8.06s, train acc=0.16, train loss=2.27, validation acc=0.15, validation loss=2.27\n",
      "Epoch 4: 10.78s, train acc=0.23, train loss=2.26, validation acc=0.22, validation loss=2.26\n",
      "Epoch 5: 13.51s, train acc=0.29, train loss=2.25, validation acc=0.29, validation loss=2.25\n",
      "Epoch 6: 16.18s, train acc=0.36, train loss=2.23, validation acc=0.36, validation loss=2.23\n",
      "Epoch 7: 18.27s, train acc=0.40, train loss=2.21, validation acc=0.39, validation loss=2.21\n",
      "Epoch 8: 20.93s, train acc=0.39, train loss=2.19, validation acc=0.39, validation loss=2.19\n",
      "Epoch 9: 23.64s, train acc=0.44, train loss=2.16, validation acc=0.43, validation loss=2.17\n",
      "Epoch 10: 26.31s, train acc=0.49, train loss=2.13, validation acc=0.48, validation loss=2.13\n",
      "Epoch 11: 29.06s, train acc=0.50, train loss=2.09, validation acc=0.49, validation loss=2.09\n",
      "Epoch 12: 31.84s, train acc=0.53, train loss=2.05, validation acc=0.52, validation loss=2.05\n",
      "Epoch 13: 34.65s, train acc=0.56, train loss=1.99, validation acc=0.55, validation loss=1.99\n",
      "Epoch 14: 37.40s, train acc=0.57, train loss=1.93, validation acc=0.56, validation loss=1.93\n",
      "Epoch 15: 40.14s, train acc=0.58, train loss=1.86, validation acc=0.58, validation loss=1.87\n",
      "Epoch 16: 42.87s, train acc=0.60, train loss=1.79, validation acc=0.59, validation loss=1.79\n",
      "Epoch 17: 45.52s, train acc=0.61, train loss=1.72, validation acc=0.61, validation loss=1.72\n",
      "Epoch 18: 48.23s, train acc=0.63, train loss=1.64, validation acc=0.62, validation loss=1.65\n",
      "Epoch 19: 50.60s, train acc=0.64, train loss=1.57, validation acc=0.64, validation loss=1.58\n",
      "Epoch 20: 53.35s, train acc=0.65, train loss=1.50, validation acc=0.65, validation loss=1.51\n",
      "\n",
      "Test acc=0.65, Test loss=1.51\n",
      "\n",
      "\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "|                                                                                                                |\n",
      "|                         Activation: sigmoid, Optimizer: momentum, Learning Rate: 0.001                         |\n",
      "|                                                                                                                |\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "Epoch 1: 2.59s, train acc=0.09, train loss=2.37, validation acc=0.09, validation loss=2.37\n",
      "Epoch 2: 5.33s, train acc=0.12, train loss=2.33, validation acc=0.11, validation loss=2.33\n",
      "Epoch 3: 8.03s, train acc=0.11, train loss=2.31, validation acc=0.11, validation loss=2.32\n",
      "Epoch 4: 10.21s, train acc=0.11, train loss=2.30, validation acc=0.11, validation loss=2.31\n",
      "Epoch 5: 13.07s, train acc=0.11, train loss=2.30, validation acc=0.11, validation loss=2.30\n",
      "Epoch 6: 15.14s, train acc=0.11, train loss=2.30, validation acc=0.11, validation loss=2.30\n",
      "Epoch 7: 17.80s, train acc=0.11, train loss=2.29, validation acc=0.11, validation loss=2.30\n",
      "Epoch 8: 19.82s, train acc=0.11, train loss=2.29, validation acc=0.11, validation loss=2.29\n",
      "Epoch 9: 22.46s, train acc=0.11, train loss=2.29, validation acc=0.11, validation loss=2.29\n",
      "Epoch 10: 24.50s, train acc=0.11, train loss=2.29, validation acc=0.11, validation loss=2.29\n",
      "Epoch 11: 27.30s, train acc=0.11, train loss=2.29, validation acc=0.11, validation loss=2.29\n",
      "Epoch 12: 29.32s, train acc=0.11, train loss=2.29, validation acc=0.11, validation loss=2.29\n",
      "Epoch 13: 32.06s, train acc=0.11, train loss=2.29, validation acc=0.11, validation loss=2.29\n",
      "Epoch 14: 34.08s, train acc=0.11, train loss=2.29, validation acc=0.11, validation loss=2.29\n",
      "Epoch 15: 36.78s, train acc=0.11, train loss=2.29, validation acc=0.11, validation loss=2.29\n",
      "Epoch 16: 39.46s, train acc=0.11, train loss=2.28, validation acc=0.11, validation loss=2.28\n",
      "Epoch 17: 42.25s, train acc=0.12, train loss=2.28, validation acc=0.11, validation loss=2.28\n",
      "Epoch 18: 44.21s, train acc=0.12, train loss=2.28, validation acc=0.12, validation loss=2.28\n",
      "Epoch 19: 46.98s, train acc=0.12, train loss=2.28, validation acc=0.12, validation loss=2.28\n",
      "Epoch 20: 49.03s, train acc=0.12, train loss=2.28, validation acc=0.12, validation loss=2.28\n",
      "\n",
      "Test acc=0.12, Test loss=2.28\n",
      "\n",
      "\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "|                                                                                                                |\n",
      "|                            Activation: sigmoid, Optimizer: adam, Learning Rate: 0.01                           |\n",
      "|                                                                                                                |\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "Epoch 1: 4.23s, train acc=0.97, train loss=0.11, validation acc=0.96, validation loss=0.15\n",
      "Epoch 2: 8.12s, train acc=0.98, train loss=0.08, validation acc=0.96, validation loss=0.13\n",
      "Epoch 3: 12.38s, train acc=0.99, train loss=0.05, validation acc=0.97, validation loss=0.11\n",
      "Epoch 4: 16.75s, train acc=0.99, train loss=0.05, validation acc=0.97, validation loss=0.11\n",
      "Epoch 5: 21.01s, train acc=0.99, train loss=0.04, validation acc=0.97, validation loss=0.10\n",
      "Epoch 6: 25.23s, train acc=0.99, train loss=0.03, validation acc=0.97, validation loss=0.11\n",
      "Epoch 7: 29.56s, train acc=0.99, train loss=0.03, validation acc=0.97, validation loss=0.11\n",
      "Epoch 8: 33.90s, train acc=1.00, train loss=0.02, validation acc=0.97, validation loss=0.11\n",
      "Epoch 9: 38.25s, train acc=0.99, train loss=0.02, validation acc=0.97, validation loss=0.11\n",
      "Epoch 10: 42.53s, train acc=1.00, train loss=0.02, validation acc=0.97, validation loss=0.11\n",
      "Epoch 11: 47.30s, train acc=1.00, train loss=0.02, validation acc=0.97, validation loss=0.12\n",
      "Epoch 12: 51.54s, train acc=0.99, train loss=0.02, validation acc=0.97, validation loss=0.13\n",
      "Epoch 13: 57.09s, train acc=1.00, train loss=0.02, validation acc=0.97, validation loss=0.12\n",
      "Epoch 14: 62.85s, train acc=1.00, train loss=0.01, validation acc=0.97, validation loss=0.13\n",
      "Epoch 15: 66.89s, train acc=1.00, train loss=0.02, validation acc=0.97, validation loss=0.15\n",
      "Epoch 16: 71.11s, train acc=1.00, train loss=0.02, validation acc=0.97, validation loss=0.13\n",
      "Epoch 17: 75.19s, train acc=1.00, train loss=0.02, validation acc=0.97, validation loss=0.13\n",
      "Epoch 18: 79.25s, train acc=1.00, train loss=0.02, validation acc=0.97, validation loss=0.14\n",
      "Epoch 19: 83.54s, train acc=1.00, train loss=0.02, validation acc=0.97, validation loss=0.15\n",
      "Epoch 20: 87.86s, train acc=1.00, train loss=0.02, validation acc=0.97, validation loss=0.14\n",
      "\n",
      "Test acc=0.97, Test loss=0.14\n",
      "\n",
      "\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "|                                                                                                                |\n",
      "|                           Activation: sigmoid, Optimizer: adam, Learning Rate: 0.001                           |\n",
      "|                                                                                                                |\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "Epoch 1: 3.37s, train acc=0.91, train loss=0.37, validation acc=0.90, validation loss=0.40\n",
      "Epoch 2: 6.57s, train acc=0.93, train loss=0.27, validation acc=0.92, validation loss=0.31\n",
      "Epoch 3: 12.37s, train acc=0.94, train loss=0.23, validation acc=0.93, validation loss=0.27\n",
      "Epoch 4: 18.44s, train acc=0.95, train loss=0.20, validation acc=0.94, validation loss=0.24\n",
      "Epoch 5: 24.53s, train acc=0.95, train loss=0.18, validation acc=0.94, validation loss=0.22\n",
      "Epoch 6: 30.58s, train acc=0.96, train loss=0.16, validation acc=0.94, validation loss=0.20\n",
      "Epoch 7: 36.81s, train acc=0.96, train loss=0.14, validation acc=0.95, validation loss=0.19\n",
      "Epoch 8: 42.94s, train acc=0.97, train loss=0.13, validation acc=0.95, validation loss=0.17\n",
      "Epoch 9: 49.11s, train acc=0.97, train loss=0.12, validation acc=0.95, validation loss=0.17\n",
      "Epoch 10: 54.29s, train acc=0.97, train loss=0.11, validation acc=0.96, validation loss=0.15\n",
      "Epoch 11: 57.71s, train acc=0.97, train loss=0.10, validation acc=0.96, validation loss=0.15\n",
      "Epoch 12: 61.11s, train acc=0.98, train loss=0.09, validation acc=0.96, validation loss=0.14\n",
      "Epoch 13: 64.56s, train acc=0.98, train loss=0.09, validation acc=0.96, validation loss=0.14\n",
      "Epoch 14: 67.97s, train acc=0.98, train loss=0.08, validation acc=0.96, validation loss=0.13\n",
      "Epoch 15: 71.41s, train acc=0.98, train loss=0.08, validation acc=0.97, validation loss=0.13\n",
      "Epoch 16: 74.79s, train acc=0.98, train loss=0.07, validation acc=0.97, validation loss=0.12\n",
      "Epoch 17: 78.21s, train acc=0.98, train loss=0.07, validation acc=0.97, validation loss=0.12\n",
      "Epoch 18: 81.63s, train acc=0.99, train loss=0.06, validation acc=0.97, validation loss=0.11\n",
      "Epoch 19: 84.86s, train acc=0.99, train loss=0.06, validation acc=0.97, validation loss=0.11\n",
      "Epoch 20: 88.32s, train acc=0.99, train loss=0.05, validation acc=0.97, validation loss=0.11\n",
      "\n",
      "Test acc=0.97, Test loss=0.11\n",
      "\n",
      "\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "|                                                                                                                |\n",
      "|                              Activation: tanh, Optimizer: sgd, Learning Rate: 0.01                             |\n",
      "|                                                                                                                |\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "Epoch 1: 2.57s, train acc=0.87, train loss=0.86, validation acc=0.86, validation loss=0.88\n",
      "Epoch 2: 5.00s, train acc=0.89, train loss=0.64, validation acc=0.88, validation loss=0.67\n",
      "Epoch 3: 7.52s, train acc=0.90, train loss=0.54, validation acc=0.89, validation loss=0.57\n",
      "Epoch 4: 10.02s, train acc=0.91, train loss=0.48, validation acc=0.90, validation loss=0.51\n",
      "Epoch 5: 12.60s, train acc=0.91, train loss=0.44, validation acc=0.90, validation loss=0.47\n",
      "Epoch 6: 15.11s, train acc=0.92, train loss=0.41, validation acc=0.90, validation loss=0.44\n",
      "Epoch 7: 17.66s, train acc=0.92, train loss=0.38, validation acc=0.91, validation loss=0.42\n",
      "Epoch 8: 20.22s, train acc=0.92, train loss=0.36, validation acc=0.91, validation loss=0.40\n",
      "Epoch 9: 22.68s, train acc=0.93, train loss=0.35, validation acc=0.91, validation loss=0.38\n",
      "Epoch 10: 25.12s, train acc=0.93, train loss=0.33, validation acc=0.91, validation loss=0.37\n",
      "Epoch 11: 27.65s, train acc=0.93, train loss=0.32, validation acc=0.92, validation loss=0.35\n",
      "Epoch 12: 30.07s, train acc=0.93, train loss=0.31, validation acc=0.92, validation loss=0.34\n",
      "Epoch 13: 32.59s, train acc=0.93, train loss=0.30, validation acc=0.92, validation loss=0.34\n",
      "Epoch 14: 35.20s, train acc=0.94, train loss=0.29, validation acc=0.92, validation loss=0.33\n",
      "Epoch 15: 37.65s, train acc=0.94, train loss=0.28, validation acc=0.92, validation loss=0.32\n",
      "Epoch 16: 40.20s, train acc=0.94, train loss=0.28, validation acc=0.93, validation loss=0.31\n",
      "Epoch 17: 42.68s, train acc=0.94, train loss=0.27, validation acc=0.93, validation loss=0.31\n",
      "Epoch 18: 45.27s, train acc=0.94, train loss=0.26, validation acc=0.93, validation loss=0.30\n",
      "Epoch 19: 47.88s, train acc=0.94, train loss=0.26, validation acc=0.93, validation loss=0.29\n",
      "Epoch 20: 50.27s, train acc=0.94, train loss=0.25, validation acc=0.93, validation loss=0.29\n",
      "\n",
      "Test acc=0.93, Test loss=0.29\n",
      "\n",
      "\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "|                                                                                                                |\n",
      "|                             Activation: tanh, Optimizer: sgd, Learning Rate: 0.001                             |\n",
      "|                                                                                                                |\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "Epoch 1: 2.44s, train acc=0.65, train loss=1.78, validation acc=0.63, validation loss=1.79\n",
      "Epoch 2: 4.87s, train acc=0.75, train loss=1.51, validation acc=0.73, validation loss=1.52\n",
      "Epoch 3: 7.40s, train acc=0.79, train loss=1.34, validation acc=0.77, validation loss=1.36\n",
      "Epoch 4: 9.98s, train acc=0.81, train loss=1.23, validation acc=0.80, validation loss=1.24\n",
      "Epoch 5: 12.59s, train acc=0.83, train loss=1.14, validation acc=0.81, validation loss=1.16\n",
      "Epoch 6: 15.02s, train acc=0.84, train loss=1.07, validation acc=0.83, validation loss=1.09\n",
      "Epoch 7: 17.56s, train acc=0.84, train loss=1.01, validation acc=0.83, validation loss=1.03\n",
      "Epoch 8: 20.13s, train acc=0.85, train loss=0.96, validation acc=0.84, validation loss=0.98\n",
      "Epoch 9: 22.70s, train acc=0.86, train loss=0.92, validation acc=0.84, validation loss=0.94\n",
      "Epoch 10: 25.21s, train acc=0.86, train loss=0.88, validation acc=0.85, validation loss=0.90\n",
      "Epoch 11: 27.70s, train acc=0.87, train loss=0.85, validation acc=0.85, validation loss=0.87\n",
      "Epoch 12: 30.27s, train acc=0.87, train loss=0.82, validation acc=0.86, validation loss=0.84\n",
      "Epoch 13: 32.70s, train acc=0.87, train loss=0.79, validation acc=0.86, validation loss=0.82\n",
      "Epoch 14: 35.19s, train acc=0.88, train loss=0.77, validation acc=0.86, validation loss=0.79\n",
      "Epoch 15: 37.64s, train acc=0.88, train loss=0.75, validation acc=0.87, validation loss=0.77\n",
      "Epoch 16: 39.87s, train acc=0.88, train loss=0.73, validation acc=0.87, validation loss=0.75\n",
      "Epoch 17: 42.09s, train acc=0.88, train loss=0.71, validation acc=0.87, validation loss=0.73\n",
      "Epoch 18: 44.53s, train acc=0.89, train loss=0.69, validation acc=0.87, validation loss=0.72\n",
      "Epoch 19: 46.88s, train acc=0.89, train loss=0.67, validation acc=0.88, validation loss=0.70\n",
      "Epoch 20: 49.37s, train acc=0.89, train loss=0.66, validation acc=0.88, validation loss=0.68\n",
      "\n",
      "Test acc=0.88, Test loss=0.68\n",
      "\n",
      "\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "|                                                                                                                |\n",
      "|                           Activation: tanh, Optimizer: momentum, Learning Rate: 0.01                           |\n",
      "|                                                                                                                |\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "Epoch 1: 2.91s, train acc=0.87, train loss=0.85, validation acc=0.86, validation loss=0.87\n",
      "Epoch 2: 6.10s, train acc=0.89, train loss=0.64, validation acc=0.88, validation loss=0.67\n",
      "Epoch 3: 10.81s, train acc=0.90, train loss=0.54, validation acc=0.89, validation loss=0.57\n",
      "Epoch 4: 16.13s, train acc=0.91, train loss=0.48, validation acc=0.89, validation loss=0.51\n",
      "Epoch 5: 21.91s, train acc=0.91, train loss=0.44, validation acc=0.90, validation loss=0.47\n",
      "Epoch 6: 27.20s, train acc=0.92, train loss=0.41, validation acc=0.90, validation loss=0.44\n",
      "Epoch 7: 32.52s, train acc=0.92, train loss=0.38, validation acc=0.91, validation loss=0.42\n",
      "Epoch 8: 37.91s, train acc=0.92, train loss=0.36, validation acc=0.91, validation loss=0.40\n",
      "Epoch 9: 43.08s, train acc=0.92, train loss=0.35, validation acc=0.91, validation loss=0.38\n",
      "Epoch 10: 48.41s, train acc=0.93, train loss=0.33, validation acc=0.91, validation loss=0.37\n",
      "Epoch 11: 53.51s, train acc=0.93, train loss=0.32, validation acc=0.91, validation loss=0.36\n",
      "Epoch 12: 58.74s, train acc=0.93, train loss=0.31, validation acc=0.92, validation loss=0.35\n",
      "Epoch 13: 63.97s, train acc=0.93, train loss=0.30, validation acc=0.92, validation loss=0.34\n",
      "Epoch 14: 69.20s, train acc=0.93, train loss=0.29, validation acc=0.92, validation loss=0.33\n",
      "Epoch 15: 74.43s, train acc=0.94, train loss=0.28, validation acc=0.92, validation loss=0.32\n",
      "Epoch 16: 79.07s, train acc=0.94, train loss=0.28, validation acc=0.92, validation loss=0.31\n",
      "Epoch 17: 83.62s, train acc=0.94, train loss=0.27, validation acc=0.93, validation loss=0.31\n",
      "Epoch 18: 88.18s, train acc=0.94, train loss=0.26, validation acc=0.93, validation loss=0.30\n",
      "Epoch 19: 92.75s, train acc=0.94, train loss=0.26, validation acc=0.93, validation loss=0.29\n",
      "Epoch 20: 97.30s, train acc=0.94, train loss=0.25, validation acc=0.93, validation loss=0.29\n",
      "\n",
      "Test acc=0.93, Test loss=0.29\n",
      "\n",
      "\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "|                                                                                                                |\n",
      "|                           Activation: tanh, Optimizer: momentum, Learning Rate: 0.001                          |\n",
      "|                                                                                                                |\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "Epoch 1: 4.55s, train acc=0.65, train loss=1.74, validation acc=0.65, validation loss=1.75\n",
      "Epoch 2: 9.09s, train acc=0.76, train loss=1.48, validation acc=0.75, validation loss=1.49\n",
      "Epoch 3: 13.58s, train acc=0.80, train loss=1.33, validation acc=0.78, validation loss=1.34\n",
      "Epoch 4: 18.07s, train acc=0.82, train loss=1.22, validation acc=0.81, validation loss=1.24\n",
      "Epoch 5: 22.34s, train acc=0.83, train loss=1.14, validation acc=0.82, validation loss=1.16\n",
      "Epoch 6: 26.49s, train acc=0.84, train loss=1.07, validation acc=0.83, validation loss=1.09\n",
      "Epoch 7: 30.74s, train acc=0.85, train loss=1.02, validation acc=0.84, validation loss=1.04\n",
      "Epoch 8: 34.83s, train acc=0.86, train loss=0.97, validation acc=0.84, validation loss=0.99\n",
      "Epoch 9: 39.12s, train acc=0.86, train loss=0.93, validation acc=0.85, validation loss=0.95\n",
      "Epoch 10: 43.31s, train acc=0.87, train loss=0.89, validation acc=0.85, validation loss=0.91\n",
      "Epoch 11: 47.58s, train acc=0.87, train loss=0.86, validation acc=0.85, validation loss=0.88\n",
      "Epoch 12: 51.92s, train acc=0.87, train loss=0.83, validation acc=0.86, validation loss=0.85\n",
      "Epoch 13: 56.16s, train acc=0.88, train loss=0.80, validation acc=0.86, validation loss=0.83\n",
      "Epoch 14: 60.42s, train acc=0.88, train loss=0.78, validation acc=0.86, validation loss=0.80\n",
      "Epoch 15: 64.64s, train acc=0.88, train loss=0.76, validation acc=0.87, validation loss=0.78\n",
      "Epoch 16: 68.93s, train acc=0.88, train loss=0.74, validation acc=0.87, validation loss=0.76\n",
      "Epoch 17: 73.31s, train acc=0.88, train loss=0.72, validation acc=0.87, validation loss=0.74\n",
      "Epoch 18: 77.57s, train acc=0.89, train loss=0.70, validation acc=0.87, validation loss=0.73\n",
      "Epoch 19: 82.18s, train acc=0.89, train loss=0.68, validation acc=0.88, validation loss=0.71\n",
      "Epoch 20: 85.65s, train acc=0.89, train loss=0.67, validation acc=0.88, validation loss=0.69\n",
      "\n",
      "Test acc=0.88, Test loss=0.69\n",
      "\n",
      "\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "|                                                                                                                |\n",
      "|                             Activation: tanh, Optimizer: adam, Learning Rate: 0.01                             |\n",
      "|                                                                                                                |\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "Epoch 1: 3.52s, train acc=0.95, train loss=0.17, validation acc=0.94, validation loss=0.22\n",
      "Epoch 2: 7.06s, train acc=0.96, train loss=0.14, validation acc=0.95, validation loss=0.19\n",
      "Epoch 3: 10.61s, train acc=0.97, train loss=0.12, validation acc=0.95, validation loss=0.17\n",
      "Epoch 4: 14.14s, train acc=0.97, train loss=0.11, validation acc=0.95, validation loss=0.17\n",
      "Epoch 5: 17.67s, train acc=0.97, train loss=0.11, validation acc=0.95, validation loss=0.17\n",
      "Epoch 6: 21.20s, train acc=0.97, train loss=0.10, validation acc=0.95, validation loss=0.17\n",
      "Epoch 7: 24.69s, train acc=0.97, train loss=0.10, validation acc=0.95, validation loss=0.17\n",
      "Epoch 8: 28.20s, train acc=0.97, train loss=0.12, validation acc=0.95, validation loss=0.18\n",
      "Epoch 9: 31.72s, train acc=0.97, train loss=0.10, validation acc=0.95, validation loss=0.18\n",
      "Epoch 10: 35.26s, train acc=0.96, train loss=0.14, validation acc=0.94, validation loss=0.21\n",
      "Epoch 11: 38.84s, train acc=0.95, train loss=0.16, validation acc=0.94, validation loss=0.23\n",
      "Epoch 12: 42.45s, train acc=0.96, train loss=0.15, validation acc=0.94, validation loss=0.22\n",
      "Epoch 13: 46.05s, train acc=0.94, train loss=0.19, validation acc=0.93, validation loss=0.26\n",
      "Epoch 14: 49.67s, train acc=0.96, train loss=0.15, validation acc=0.94, validation loss=0.23\n",
      "Epoch 15: 53.29s, train acc=0.94, train loss=0.20, validation acc=0.93, validation loss=0.27\n",
      "Epoch 16: 56.88s, train acc=0.94, train loss=0.21, validation acc=0.92, validation loss=0.28\n",
      "Epoch 17: 60.26s, train acc=0.94, train loss=0.21, validation acc=0.92, validation loss=0.28\n",
      "Epoch 18: 63.90s, train acc=0.94, train loss=0.21, validation acc=0.92, validation loss=0.28\n",
      "Epoch 19: 67.42s, train acc=0.89, train loss=0.37, validation acc=0.88, validation loss=0.43\n",
      "Epoch 20: 71.05s, train acc=0.91, train loss=0.30, validation acc=0.90, validation loss=0.39\n",
      "\n",
      "Test acc=0.90, Test loss=0.39\n",
      "\n",
      "\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "|                                                                                                                |\n",
      "|                             Activation: tanh, Optimizer: adam, Learning Rate: 0.001                            |\n",
      "|                                                                                                                |\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "Epoch 1: 3.53s, train acc=0.94, train loss=0.26, validation acc=0.93, validation loss=0.30\n",
      "Epoch 2: 7.19s, train acc=0.96, train loss=0.20, validation acc=0.95, validation loss=0.23\n",
      "Epoch 3: 10.80s, train acc=0.97, train loss=0.16, validation acc=0.95, validation loss=0.20\n",
      "Epoch 4: 14.44s, train acc=0.97, train loss=0.14, validation acc=0.96, validation loss=0.18\n",
      "Epoch 5: 18.04s, train acc=0.98, train loss=0.12, validation acc=0.96, validation loss=0.16\n",
      "Epoch 6: 21.65s, train acc=0.98, train loss=0.11, validation acc=0.96, validation loss=0.15\n",
      "Epoch 7: 25.27s, train acc=0.98, train loss=0.09, validation acc=0.97, validation loss=0.13\n",
      "Epoch 8: 28.87s, train acc=0.98, train loss=0.08, validation acc=0.97, validation loss=0.13\n",
      "Epoch 9: 32.41s, train acc=0.99, train loss=0.07, validation acc=0.97, validation loss=0.12\n",
      "Epoch 10: 36.01s, train acc=0.99, train loss=0.07, validation acc=0.97, validation loss=0.12\n",
      "Epoch 11: 39.62s, train acc=0.99, train loss=0.06, validation acc=0.97, validation loss=0.11\n",
      "Epoch 12: 43.20s, train acc=0.99, train loss=0.05, validation acc=0.97, validation loss=0.11\n",
      "Epoch 13: 46.74s, train acc=0.99, train loss=0.05, validation acc=0.97, validation loss=0.10\n",
      "Epoch 14: 50.34s, train acc=0.99, train loss=0.04, validation acc=0.97, validation loss=0.10\n",
      "Epoch 15: 53.93s, train acc=0.99, train loss=0.04, validation acc=0.97, validation loss=0.10\n",
      "Epoch 16: 57.52s, train acc=0.99, train loss=0.04, validation acc=0.97, validation loss=0.10\n",
      "Epoch 17: 61.12s, train acc=0.99, train loss=0.03, validation acc=0.97, validation loss=0.10\n",
      "Epoch 18: 64.72s, train acc=0.99, train loss=0.03, validation acc=0.97, validation loss=0.10\n",
      "Epoch 19: 68.34s, train acc=0.99, train loss=0.03, validation acc=0.97, validation loss=0.10\n",
      "Epoch 20: 71.87s, train acc=1.00, train loss=0.03, validation acc=0.97, validation loss=0.09\n",
      "\n",
      "Test acc=0.97, Test loss=0.09\n",
      "\n",
      "\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "|                                                                                                                |\n",
      "|                           Activation: leaky_relu, Optimizer: sgd, Learning Rate: 0.01                          |\n",
      "|                                                                                                                |\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "Epoch 1: 1.60s, train acc=0.80, train loss=0.75, validation acc=0.79, validation loss=0.79\n",
      "Epoch 2: 3.44s, train acc=0.89, train loss=0.40, validation acc=0.89, validation loss=0.43\n",
      "Epoch 3: 5.39s, train acc=0.91, train loss=0.32, validation acc=0.90, validation loss=0.36\n",
      "Epoch 4: 7.38s, train acc=0.92, train loss=0.30, validation acc=0.91, validation loss=0.34\n",
      "Epoch 5: 9.19s, train acc=0.92, train loss=0.27, validation acc=0.91, validation loss=0.32\n",
      "Epoch 6: 11.06s, train acc=0.93, train loss=0.25, validation acc=0.92, validation loss=0.30\n",
      "Epoch 7: 12.93s, train acc=0.93, train loss=0.24, validation acc=0.92, validation loss=0.29\n",
      "Epoch 8: 14.59s, train acc=0.94, train loss=0.23, validation acc=0.92, validation loss=0.28\n",
      "Epoch 9: 16.45s, train acc=0.94, train loss=0.22, validation acc=0.93, validation loss=0.27\n",
      "Epoch 10: 18.24s, train acc=0.94, train loss=0.21, validation acc=0.93, validation loss=0.25\n",
      "Epoch 11: 19.89s, train acc=0.94, train loss=0.20, validation acc=0.93, validation loss=0.25\n",
      "Epoch 12: 21.61s, train acc=0.95, train loss=0.19, validation acc=0.94, validation loss=0.24\n",
      "Epoch 13: 23.22s, train acc=0.95, train loss=0.19, validation acc=0.94, validation loss=0.23\n",
      "Epoch 14: 24.95s, train acc=0.95, train loss=0.18, validation acc=0.94, validation loss=0.23\n",
      "Epoch 15: 26.78s, train acc=0.95, train loss=0.17, validation acc=0.94, validation loss=0.22\n",
      "Epoch 16: 28.63s, train acc=0.96, train loss=0.17, validation acc=0.94, validation loss=0.22\n",
      "Epoch 17: 30.48s, train acc=0.96, train loss=0.16, validation acc=0.94, validation loss=0.21\n",
      "Epoch 18: 32.21s, train acc=0.96, train loss=0.16, validation acc=0.94, validation loss=0.21\n",
      "Epoch 19: 34.08s, train acc=0.96, train loss=0.15, validation acc=0.95, validation loss=0.20\n",
      "Epoch 20: 35.90s, train acc=0.96, train loss=0.15, validation acc=0.95, validation loss=0.20\n",
      "\n",
      "Test acc=0.95, Test loss=0.20\n",
      "\n",
      "\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "|                                                                                                                |\n",
      "|                          Activation: leaky_relu, Optimizer: sgd, Learning Rate: 0.001                          |\n",
      "|                                                                                                                |\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "Epoch 1: 1.53s, train acc=0.26, train loss=2.26, validation acc=0.26, validation loss=2.26\n",
      "Epoch 2: 3.30s, train acc=0.39, train loss=2.13, validation acc=0.39, validation loss=2.13\n",
      "Epoch 3: 4.87s, train acc=0.46, train loss=1.96, validation acc=0.46, validation loss=1.96\n",
      "Epoch 4: 6.62s, train acc=0.51, train loss=1.79, validation acc=0.51, validation loss=1.79\n",
      "Epoch 5: 8.43s, train acc=0.55, train loss=1.63, validation acc=0.54, validation loss=1.64\n",
      "Epoch 6: 10.40s, train acc=0.56, train loss=1.51, validation acc=0.56, validation loss=1.51\n",
      "Epoch 7: 12.31s, train acc=0.58, train loss=1.38, validation acc=0.57, validation loss=1.39\n",
      "Epoch 8: 14.32s, train acc=0.69, train loss=1.23, validation acc=0.69, validation loss=1.24\n",
      "Epoch 9: 16.26s, train acc=0.74, train loss=1.08, validation acc=0.73, validation loss=1.09\n",
      "Epoch 10: 17.90s, train acc=0.76, train loss=0.94, validation acc=0.75, validation loss=0.95\n",
      "Epoch 11: 19.77s, train acc=0.77, train loss=0.81, validation acc=0.76, validation loss=0.83\n",
      "Epoch 12: 21.60s, train acc=0.86, train loss=0.61, validation acc=0.85, validation loss=0.63\n",
      "Epoch 13: 23.51s, train acc=0.87, train loss=0.53, validation acc=0.86, validation loss=0.56\n",
      "Epoch 14: 25.42s, train acc=0.88, train loss=0.49, validation acc=0.87, validation loss=0.51\n",
      "Epoch 15: 27.00s, train acc=0.88, train loss=0.45, validation acc=0.87, validation loss=0.48\n",
      "Epoch 16: 28.71s, train acc=0.89, train loss=0.43, validation acc=0.88, validation loss=0.46\n",
      "Epoch 17: 30.30s, train acc=0.89, train loss=0.41, validation acc=0.88, validation loss=0.44\n",
      "Epoch 18: 32.16s, train acc=0.89, train loss=0.39, validation acc=0.88, validation loss=0.43\n",
      "Epoch 19: 34.06s, train acc=0.90, train loss=0.38, validation acc=0.89, validation loss=0.41\n",
      "Epoch 20: 35.74s, train acc=0.90, train loss=0.37, validation acc=0.89, validation loss=0.40\n",
      "\n",
      "Test acc=0.89, Test loss=0.40\n",
      "\n",
      "\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "|                                                                                                                |\n",
      "|                        Activation: leaky_relu, Optimizer: momentum, Learning Rate: 0.01                        |\n",
      "|                                                                                                                |\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "Epoch 1: 2.42s, train acc=0.80, train loss=0.76, validation acc=0.80, validation loss=0.78\n",
      "Epoch 2: 4.92s, train acc=0.89, train loss=0.39, validation acc=0.88, validation loss=0.43\n",
      "Epoch 3: 7.23s, train acc=0.91, train loss=0.32, validation acc=0.90, validation loss=0.37\n",
      "Epoch 4: 9.61s, train acc=0.92, train loss=0.29, validation acc=0.90, validation loss=0.33\n",
      "Epoch 5: 12.06s, train acc=0.93, train loss=0.26, validation acc=0.91, validation loss=0.31\n",
      "Epoch 6: 14.48s, train acc=0.93, train loss=0.25, validation acc=0.92, validation loss=0.29\n",
      "Epoch 7: 16.86s, train acc=0.93, train loss=0.23, validation acc=0.92, validation loss=0.28\n",
      "Epoch 8: 19.33s, train acc=0.94, train loss=0.22, validation acc=0.93, validation loss=0.26\n",
      "Epoch 9: 21.78s, train acc=0.94, train loss=0.20, validation acc=0.93, validation loss=0.25\n",
      "Epoch 10: 24.15s, train acc=0.95, train loss=0.19, validation acc=0.93, validation loss=0.24\n",
      "Epoch 11: 26.37s, train acc=0.95, train loss=0.18, validation acc=0.94, validation loss=0.23\n",
      "Epoch 12: 28.76s, train acc=0.95, train loss=0.17, validation acc=0.94, validation loss=0.22\n",
      "Epoch 13: 31.15s, train acc=0.95, train loss=0.16, validation acc=0.94, validation loss=0.21\n",
      "Epoch 14: 33.67s, train acc=0.96, train loss=0.16, validation acc=0.94, validation loss=0.21\n",
      "Epoch 15: 36.14s, train acc=0.96, train loss=0.15, validation acc=0.94, validation loss=0.20\n",
      "Epoch 16: 38.50s, train acc=0.96, train loss=0.14, validation acc=0.95, validation loss=0.19\n",
      "Epoch 17: 40.87s, train acc=0.96, train loss=0.14, validation acc=0.95, validation loss=0.19\n",
      "Epoch 18: 43.24s, train acc=0.96, train loss=0.13, validation acc=0.95, validation loss=0.18\n",
      "Epoch 19: 45.52s, train acc=0.97, train loss=0.12, validation acc=0.95, validation loss=0.17\n",
      "Epoch 20: 47.95s, train acc=0.97, train loss=0.12, validation acc=0.95, validation loss=0.17\n",
      "\n",
      "Test acc=0.95, Test loss=0.17\n",
      "\n",
      "\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "|                                                                                                                |\n",
      "|                        Activation: leaky_relu, Optimizer: momentum, Learning Rate: 0.001                       |\n",
      "|                                                                                                                |\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "Epoch 1: 3.06s, train acc=0.37, train loss=2.18, validation acc=0.36, validation loss=2.19\n",
      "Epoch 2: 6.18s, train acc=0.42, train loss=2.00, validation acc=0.41, validation loss=2.01\n",
      "Epoch 3: 9.23s, train acc=0.53, train loss=1.76, validation acc=0.52, validation loss=1.78\n",
      "Epoch 4: 12.28s, train acc=0.60, train loss=1.52, validation acc=0.58, validation loss=1.55\n",
      "Epoch 5: 15.37s, train acc=0.65, train loss=1.29, validation acc=0.63, validation loss=1.31\n",
      "Epoch 6: 18.12s, train acc=0.73, train loss=1.13, validation acc=0.71, validation loss=1.15\n",
      "Epoch 7: 21.17s, train acc=0.76, train loss=1.02, validation acc=0.74, validation loss=1.04\n",
      "Epoch 8: 24.22s, train acc=0.77, train loss=0.93, validation acc=0.76, validation loss=0.96\n",
      "Epoch 9: 27.28s, train acc=0.78, train loss=0.87, validation acc=0.77, validation loss=0.90\n",
      "Epoch 10: 30.45s, train acc=0.79, train loss=0.82, validation acc=0.78, validation loss=0.85\n",
      "Epoch 11: 33.60s, train acc=0.79, train loss=0.77, validation acc=0.78, validation loss=0.80\n",
      "Epoch 12: 36.76s, train acc=0.80, train loss=0.73, validation acc=0.79, validation loss=0.76\n",
      "Epoch 13: 39.90s, train acc=0.80, train loss=0.70, validation acc=0.79, validation loss=0.73\n",
      "Epoch 14: 42.97s, train acc=0.80, train loss=0.67, validation acc=0.79, validation loss=0.70\n",
      "Epoch 15: 46.06s, train acc=0.81, train loss=0.64, validation acc=0.80, validation loss=0.68\n",
      "Epoch 16: 49.19s, train acc=0.81, train loss=0.62, validation acc=0.80, validation loss=0.65\n",
      "Epoch 17: 52.35s, train acc=0.81, train loss=0.60, validation acc=0.80, validation loss=0.63\n",
      "Epoch 18: 55.41s, train acc=0.81, train loss=0.58, validation acc=0.80, validation loss=0.62\n",
      "Epoch 19: 58.46s, train acc=0.81, train loss=0.56, validation acc=0.80, validation loss=0.60\n",
      "Epoch 20: 61.52s, train acc=0.82, train loss=0.55, validation acc=0.81, validation loss=0.58\n",
      "\n",
      "Test acc=0.81, Test loss=0.58\n",
      "\n",
      "\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "|                                                                                                                |\n",
      "|                          Activation: leaky_relu, Optimizer: adam, Learning Rate: 0.01                          |\n",
      "|                                                                                                                |\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "Epoch 1: 3.83s, train acc=0.94, train loss=0.21, validation acc=0.92, validation loss=0.26\n",
      "Epoch 2: 7.64s, train acc=0.96, train loss=0.14, validation acc=0.94, validation loss=0.19\n",
      "Epoch 3: 11.51s, train acc=0.96, train loss=0.13, validation acc=0.95, validation loss=0.19\n",
      "Epoch 4: 15.38s, train acc=0.96, train loss=0.13, validation acc=0.95, validation loss=0.18\n",
      "Epoch 5: 19.21s, train acc=0.97, train loss=0.12, validation acc=0.95, validation loss=0.19\n",
      "Epoch 6: 23.07s, train acc=0.97, train loss=0.09, validation acc=0.96, validation loss=0.16\n",
      "Epoch 7: 26.93s, train acc=0.98, train loss=0.08, validation acc=0.96, validation loss=0.15\n",
      "Epoch 8: 30.78s, train acc=0.98, train loss=0.08, validation acc=0.96, validation loss=0.17\n",
      "Epoch 9: 34.58s, train acc=0.98, train loss=0.06, validation acc=0.96, validation loss=0.15\n",
      "Epoch 10: 38.39s, train acc=0.98, train loss=0.05, validation acc=0.96, validation loss=0.14\n",
      "Epoch 11: 42.22s, train acc=0.98, train loss=0.05, validation acc=0.96, validation loss=0.15\n",
      "Epoch 12: 46.06s, train acc=0.99, train loss=0.04, validation acc=0.96, validation loss=0.15\n",
      "Epoch 13: 49.91s, train acc=0.98, train loss=0.06, validation acc=0.96, validation loss=0.17\n",
      "Epoch 14: 53.74s, train acc=0.99, train loss=0.04, validation acc=0.96, validation loss=0.15\n",
      "Epoch 15: 57.57s, train acc=0.99, train loss=0.03, validation acc=0.97, validation loss=0.15\n",
      "Epoch 16: 61.39s, train acc=0.99, train loss=0.04, validation acc=0.97, validation loss=0.17\n",
      "Epoch 17: 65.19s, train acc=0.99, train loss=0.04, validation acc=0.96, validation loss=0.18\n",
      "Epoch 18: 69.04s, train acc=0.99, train loss=0.04, validation acc=0.96, validation loss=0.18\n",
      "Epoch 19: 72.90s, train acc=0.99, train loss=0.02, validation acc=0.97, validation loss=0.16\n",
      "Epoch 20: 76.69s, train acc=0.99, train loss=0.04, validation acc=0.96, validation loss=0.18\n",
      "\n",
      "Test acc=0.96, Test loss=0.18\n",
      "\n",
      "\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "|                                                                                                                |\n",
      "|                          Activation: leaky_relu, Optimizer: adam, Learning Rate: 0.001                         |\n",
      "|                                                                                                                |\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "Epoch 1: 3.99s, train acc=0.95, train loss=0.16, validation acc=0.94, validation loss=0.21\n",
      "Epoch 2: 7.90s, train acc=0.97, train loss=0.12, validation acc=0.95, validation loss=0.16\n",
      "Epoch 3: 11.89s, train acc=0.97, train loss=0.09, validation acc=0.96, validation loss=0.14\n",
      "Epoch 4: 15.85s, train acc=0.98, train loss=0.08, validation acc=0.96, validation loss=0.13\n",
      "Epoch 5: 19.85s, train acc=0.98, train loss=0.06, validation acc=0.97, validation loss=0.12\n",
      "Epoch 6: 23.81s, train acc=0.99, train loss=0.05, validation acc=0.97, validation loss=0.11\n",
      "Epoch 7: 27.79s, train acc=0.99, train loss=0.04, validation acc=0.97, validation loss=0.11\n",
      "Epoch 8: 31.78s, train acc=0.99, train loss=0.04, validation acc=0.97, validation loss=0.11\n",
      "Epoch 9: 35.77s, train acc=0.99, train loss=0.03, validation acc=0.97, validation loss=0.10\n",
      "Epoch 10: 39.74s, train acc=0.99, train loss=0.03, validation acc=0.97, validation loss=0.10\n",
      "Epoch 11: 43.71s, train acc=0.99, train loss=0.03, validation acc=0.97, validation loss=0.10\n",
      "Epoch 12: 47.68s, train acc=0.99, train loss=0.02, validation acc=0.97, validation loss=0.10\n",
      "Epoch 13: 51.68s, train acc=1.00, train loss=0.02, validation acc=0.97, validation loss=0.10\n",
      "Epoch 14: 55.70s, train acc=1.00, train loss=0.02, validation acc=0.97, validation loss=0.11\n",
      "Epoch 15: 59.68s, train acc=1.00, train loss=0.01, validation acc=0.97, validation loss=0.10\n",
      "Epoch 16: 63.63s, train acc=1.00, train loss=0.01, validation acc=0.97, validation loss=0.11\n",
      "Epoch 17: 67.60s, train acc=1.00, train loss=0.01, validation acc=0.97, validation loss=0.11\n",
      "Epoch 18: 71.58s, train acc=1.00, train loss=0.01, validation acc=0.97, validation loss=0.11\n",
      "Epoch 19: 75.50s, train acc=1.00, train loss=0.01, validation acc=0.98, validation loss=0.11\n",
      "Epoch 20: 79.50s, train acc=1.00, train loss=0.01, validation acc=0.98, validation loss=0.12\n",
      "\n",
      "Test acc=0.98, Test loss=0.12\n",
      "\n",
      "\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "|                                                                                                                |\n",
      "|                              Activation: selu, Optimizer: sgd, Learning Rate: 0.01                             |\n",
      "|                                                                                                                |\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "Epoch 1: 2.63s, train acc=0.90, train loss=0.37, validation acc=0.89, validation loss=0.41\n",
      "Epoch 2: 5.00s, train acc=0.91, train loss=0.31, validation acc=0.90, validation loss=0.35\n",
      "Epoch 3: 7.27s, train acc=0.92, train loss=0.28, validation acc=0.91, validation loss=0.33\n",
      "Epoch 4: 9.59s, train acc=0.93, train loss=0.26, validation acc=0.91, validation loss=0.31\n",
      "Epoch 5: 11.82s, train acc=0.93, train loss=0.25, validation acc=0.91, validation loss=0.30\n",
      "Epoch 6: 14.19s, train acc=0.93, train loss=0.23, validation acc=0.92, validation loss=0.28\n",
      "Epoch 7: 16.51s, train acc=0.94, train loss=0.22, validation acc=0.92, validation loss=0.28\n",
      "Epoch 8: 18.96s, train acc=0.94, train loss=0.21, validation acc=0.93, validation loss=0.27\n",
      "Epoch 9: 21.33s, train acc=0.94, train loss=0.20, validation acc=0.93, validation loss=0.26\n",
      "Epoch 10: 23.72s, train acc=0.94, train loss=0.19, validation acc=0.93, validation loss=0.25\n",
      "Epoch 11: 25.99s, train acc=0.95, train loss=0.18, validation acc=0.93, validation loss=0.24\n",
      "Epoch 12: 28.25s, train acc=0.95, train loss=0.18, validation acc=0.94, validation loss=0.23\n",
      "Epoch 13: 30.57s, train acc=0.95, train loss=0.17, validation acc=0.94, validation loss=0.23\n",
      "Epoch 14: 32.63s, train acc=0.95, train loss=0.16, validation acc=0.94, validation loss=0.22\n",
      "Epoch 15: 34.94s, train acc=0.96, train loss=0.15, validation acc=0.94, validation loss=0.21\n",
      "Epoch 16: 37.34s, train acc=0.96, train loss=0.15, validation acc=0.94, validation loss=0.21\n",
      "Epoch 17: 39.68s, train acc=0.96, train loss=0.14, validation acc=0.94, validation loss=0.20\n",
      "Epoch 18: 41.97s, train acc=0.96, train loss=0.14, validation acc=0.94, validation loss=0.20\n",
      "Epoch 19: 44.31s, train acc=0.96, train loss=0.13, validation acc=0.95, validation loss=0.19\n",
      "Epoch 20: 46.66s, train acc=0.96, train loss=0.13, validation acc=0.95, validation loss=0.18\n",
      "\n",
      "Test acc=0.95, Test loss=0.18\n",
      "\n",
      "\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "|                                                                                                                |\n",
      "|                             Activation: selu, Optimizer: sgd, Learning Rate: 0.001                             |\n",
      "|                                                                                                                |\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "Epoch 1: 2.56s, train acc=0.79, train loss=1.02, validation acc=0.78, validation loss=1.04\n",
      "Epoch 2: 5.25s, train acc=0.84, train loss=0.71, validation acc=0.83, validation loss=0.74\n",
      "Epoch 3: 7.97s, train acc=0.86, train loss=0.58, validation acc=0.85, validation loss=0.61\n",
      "Epoch 4: 10.58s, train acc=0.87, train loss=0.51, validation acc=0.86, validation loss=0.54\n",
      "Epoch 5: 13.19s, train acc=0.88, train loss=0.46, validation acc=0.87, validation loss=0.50\n",
      "Epoch 6: 15.89s, train acc=0.89, train loss=0.43, validation acc=0.88, validation loss=0.47\n",
      "Epoch 7: 18.62s, train acc=0.89, train loss=0.41, validation acc=0.88, validation loss=0.44\n",
      "Epoch 8: 21.29s, train acc=0.89, train loss=0.39, validation acc=0.88, validation loss=0.43\n",
      "Epoch 9: 23.87s, train acc=0.90, train loss=0.37, validation acc=0.89, validation loss=0.41\n",
      "Epoch 10: 26.51s, train acc=0.90, train loss=0.36, validation acc=0.89, validation loss=0.40\n",
      "Epoch 11: 29.21s, train acc=0.90, train loss=0.35, validation acc=0.89, validation loss=0.39\n",
      "Epoch 12: 31.91s, train acc=0.90, train loss=0.34, validation acc=0.89, validation loss=0.38\n",
      "Epoch 13: 34.57s, train acc=0.91, train loss=0.34, validation acc=0.90, validation loss=0.38\n",
      "Epoch 14: 37.27s, train acc=0.91, train loss=0.33, validation acc=0.90, validation loss=0.37\n",
      "Epoch 15: 39.97s, train acc=0.91, train loss=0.32, validation acc=0.90, validation loss=0.36\n",
      "Epoch 16: 42.68s, train acc=0.91, train loss=0.32, validation acc=0.90, validation loss=0.36\n",
      "Epoch 17: 45.28s, train acc=0.91, train loss=0.31, validation acc=0.90, validation loss=0.36\n",
      "Epoch 18: 47.98s, train acc=0.91, train loss=0.31, validation acc=0.90, validation loss=0.35\n",
      "Epoch 19: 50.68s, train acc=0.91, train loss=0.31, validation acc=0.90, validation loss=0.35\n",
      "Epoch 20: 53.29s, train acc=0.91, train loss=0.30, validation acc=0.90, validation loss=0.34\n",
      "\n",
      "Test acc=0.90, Test loss=0.34\n",
      "\n",
      "\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "|                                                                                                                |\n",
      "|                           Activation: selu, Optimizer: momentum, Learning Rate: 0.01                           |\n",
      "|                                                                                                                |\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "Epoch 1: 3.07s, train acc=0.90, train loss=0.37, validation acc=0.89, validation loss=0.40\n",
      "Epoch 2: 6.19s, train acc=0.91, train loss=0.31, validation acc=0.90, validation loss=0.35\n",
      "Epoch 3: 9.25s, train acc=0.92, train loss=0.28, validation acc=0.91, validation loss=0.32\n",
      "Epoch 4: 12.37s, train acc=0.92, train loss=0.26, validation acc=0.91, validation loss=0.31\n",
      "Epoch 5: 15.29s, train acc=0.93, train loss=0.25, validation acc=0.92, validation loss=0.29\n",
      "Epoch 6: 18.32s, train acc=0.93, train loss=0.23, validation acc=0.92, validation loss=0.28\n",
      "Epoch 7: 21.35s, train acc=0.94, train loss=0.22, validation acc=0.92, validation loss=0.27\n",
      "Epoch 8: 24.46s, train acc=0.94, train loss=0.21, validation acc=0.93, validation loss=0.26\n",
      "Epoch 9: 27.60s, train acc=0.94, train loss=0.20, validation acc=0.93, validation loss=0.25\n",
      "Epoch 10: 30.63s, train acc=0.95, train loss=0.19, validation acc=0.93, validation loss=0.24\n",
      "Epoch 11: 33.73s, train acc=0.95, train loss=0.19, validation acc=0.93, validation loss=0.24\n",
      "Epoch 12: 36.82s, train acc=0.95, train loss=0.17, validation acc=0.94, validation loss=0.23\n",
      "Epoch 13: 39.92s, train acc=0.95, train loss=0.17, validation acc=0.94, validation loss=0.22\n",
      "Epoch 14: 43.01s, train acc=0.95, train loss=0.16, validation acc=0.94, validation loss=0.21\n",
      "Epoch 15: 46.06s, train acc=0.96, train loss=0.15, validation acc=0.94, validation loss=0.21\n",
      "Epoch 16: 49.10s, train acc=0.96, train loss=0.15, validation acc=0.94, validation loss=0.20\n",
      "Epoch 17: 52.17s, train acc=0.96, train loss=0.14, validation acc=0.94, validation loss=0.20\n",
      "Epoch 18: 55.24s, train acc=0.96, train loss=0.14, validation acc=0.95, validation loss=0.19\n",
      "Epoch 19: 58.31s, train acc=0.96, train loss=0.13, validation acc=0.95, validation loss=0.18\n",
      "Epoch 20: 61.35s, train acc=0.96, train loss=0.13, validation acc=0.95, validation loss=0.18\n",
      "\n",
      "Test acc=0.95, Test loss=0.18\n",
      "\n",
      "\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "|                                                                                                                |\n",
      "|                           Activation: selu, Optimizer: momentum, Learning Rate: 0.001                          |\n",
      "|                                                                                                                |\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "Epoch 1: 3.11s, train acc=0.78, train loss=1.08, validation acc=0.77, validation loss=1.10\n",
      "Epoch 2: 6.20s, train acc=0.83, train loss=0.74, validation acc=0.82, validation loss=0.76\n",
      "Epoch 3: 9.26s, train acc=0.85, train loss=0.60, validation acc=0.84, validation loss=0.63\n",
      "Epoch 4: 12.32s, train acc=0.87, train loss=0.52, validation acc=0.85, validation loss=0.55\n",
      "Epoch 5: 15.44s, train acc=0.88, train loss=0.47, validation acc=0.86, validation loss=0.51\n",
      "Epoch 6: 18.47s, train acc=0.88, train loss=0.44, validation acc=0.87, validation loss=0.47\n",
      "Epoch 7: 21.49s, train acc=0.89, train loss=0.42, validation acc=0.88, validation loss=0.45\n",
      "Epoch 8: 24.51s, train acc=0.89, train loss=0.40, validation acc=0.88, validation loss=0.43\n",
      "Epoch 9: 27.60s, train acc=0.89, train loss=0.38, validation acc=0.88, validation loss=0.42\n",
      "Epoch 10: 30.63s, train acc=0.90, train loss=0.37, validation acc=0.89, validation loss=0.41\n",
      "Epoch 11: 33.69s, train acc=0.90, train loss=0.36, validation acc=0.89, validation loss=0.40\n",
      "Epoch 12: 36.80s, train acc=0.90, train loss=0.35, validation acc=0.89, validation loss=0.39\n",
      "Epoch 13: 39.85s, train acc=0.90, train loss=0.34, validation acc=0.89, validation loss=0.38\n",
      "Epoch 14: 42.94s, train acc=0.91, train loss=0.34, validation acc=0.89, validation loss=0.38\n",
      "Epoch 15: 46.05s, train acc=0.91, train loss=0.33, validation acc=0.90, validation loss=0.37\n",
      "Epoch 16: 49.03s, train acc=0.91, train loss=0.32, validation acc=0.90, validation loss=0.36\n",
      "Epoch 17: 52.08s, train acc=0.91, train loss=0.32, validation acc=0.90, validation loss=0.36\n",
      "Epoch 18: 55.08s, train acc=0.91, train loss=0.31, validation acc=0.90, validation loss=0.36\n",
      "Epoch 19: 58.11s, train acc=0.91, train loss=0.31, validation acc=0.90, validation loss=0.35\n",
      "Epoch 20: 61.19s, train acc=0.91, train loss=0.31, validation acc=0.90, validation loss=0.35\n",
      "\n",
      "Test acc=0.90, Test loss=0.35\n",
      "\n",
      "\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "|                                                                                                                |\n",
      "|                             Activation: selu, Optimizer: adam, Learning Rate: 0.01                             |\n",
      "|                                                                                                                |\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "Epoch 1: 3.83s, train acc=0.35, train loss=4.76, validation acc=0.34, validation loss=4.94\n",
      "Epoch 2: 7.67s, train acc=0.33, train loss=4.57, validation acc=0.32, validation loss=4.74\n",
      "Epoch 3: 11.55s, train acc=0.16, train loss=5.64, validation acc=0.16, validation loss=5.79\n",
      "Epoch 4: 15.38s, train acc=0.11, train loss=9.55, validation acc=0.11, validation loss=9.72\n",
      "Epoch 5: 19.30s, train acc=0.37, train loss=4.99, validation acc=0.37, validation loss=5.10\n",
      "Epoch 6: 23.14s, train acc=0.18, train loss=11.86, validation acc=0.17, validation loss=11.95\n",
      "Epoch 7: 27.01s, train acc=0.14, train loss=13.32, validation acc=0.13, validation loss=13.36\n",
      "Epoch 8: 30.84s, train acc=0.21, train loss=11.23, validation acc=0.21, validation loss=11.37\n",
      "Epoch 9: 34.71s, train acc=0.18, train loss=11.92, validation acc=0.18, validation loss=12.06\n",
      "Epoch 10: 38.59s, train acc=0.19, train loss=11.80, validation acc=0.18, validation loss=11.94\n",
      "Epoch 11: 42.47s, train acc=0.12, train loss=15.45, validation acc=0.12, validation loss=15.58\n",
      "Epoch 12: 46.30s, train acc=0.08, train loss=15.02, validation acc=0.08, validation loss=15.14\n",
      "Epoch 13: 50.14s, train acc=0.08, train loss=15.05, validation acc=0.08, validation loss=15.18\n",
      "Epoch 14: 53.98s, train acc=0.08, train loss=15.09, validation acc=0.08, validation loss=15.22\n",
      "Epoch 15: 57.81s, train acc=0.07, train loss=15.12, validation acc=0.07, validation loss=15.25\n",
      "Epoch 16: 61.71s, train acc=0.07, train loss=15.15, validation acc=0.07, validation loss=15.28\n",
      "Epoch 17: 65.57s, train acc=0.06, train loss=15.18, validation acc=0.06, validation loss=15.32\n",
      "Epoch 18: 69.44s, train acc=0.06, train loss=15.21, validation acc=0.07, validation loss=15.35\n",
      "Epoch 19: 73.27s, train acc=0.07, train loss=15.25, validation acc=0.07, validation loss=15.39\n",
      "Epoch 20: 77.15s, train acc=0.08, train loss=15.30, validation acc=0.08, validation loss=15.44\n",
      "\n",
      "Test acc=0.08, Test loss=15.44\n",
      "\n",
      "\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "|                                                                                                                |\n",
      "|                             Activation: selu, Optimizer: adam, Learning Rate: 0.001                            |\n",
      "|                                                                                                                |\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "Epoch 1: 3.82s, train acc=0.94, train loss=0.20, validation acc=0.93, validation loss=0.24\n",
      "Epoch 2: 7.66s, train acc=0.96, train loss=0.15, validation acc=0.94, validation loss=0.20\n",
      "Epoch 3: 11.57s, train acc=0.97, train loss=0.12, validation acc=0.95, validation loss=0.18\n",
      "Epoch 4: 15.41s, train acc=0.97, train loss=0.10, validation acc=0.95, validation loss=0.16\n",
      "Epoch 5: 19.28s, train acc=0.97, train loss=0.09, validation acc=0.96, validation loss=0.15\n",
      "Epoch 6: 23.14s, train acc=0.98, train loss=0.08, validation acc=0.96, validation loss=0.14\n",
      "Epoch 7: 27.02s, train acc=0.98, train loss=0.07, validation acc=0.96, validation loss=0.13\n",
      "Epoch 8: 30.91s, train acc=0.98, train loss=0.06, validation acc=0.97, validation loss=0.12\n",
      "Epoch 9: 34.77s, train acc=0.99, train loss=0.05, validation acc=0.97, validation loss=0.12\n",
      "Epoch 10: 38.59s, train acc=0.99, train loss=0.05, validation acc=0.97, validation loss=0.12\n",
      "Epoch 11: 42.50s, train acc=0.99, train loss=0.04, validation acc=0.97, validation loss=0.12\n",
      "Epoch 12: 46.40s, train acc=0.99, train loss=0.03, validation acc=0.97, validation loss=0.11\n",
      "Epoch 13: 50.28s, train acc=0.99, train loss=0.03, validation acc=0.97, validation loss=0.11\n",
      "Epoch 14: 54.13s, train acc=0.99, train loss=0.03, validation acc=0.97, validation loss=0.11\n",
      "Epoch 15: 58.03s, train acc=0.99, train loss=0.02, validation acc=0.97, validation loss=0.11\n",
      "Epoch 16: 61.89s, train acc=1.00, train loss=0.02, validation acc=0.97, validation loss=0.11\n",
      "Epoch 17: 65.77s, train acc=1.00, train loss=0.02, validation acc=0.97, validation loss=0.11\n",
      "Epoch 18: 69.65s, train acc=1.00, train loss=0.02, validation acc=0.97, validation loss=0.11\n",
      "Epoch 19: 73.53s, train acc=1.00, train loss=0.02, validation acc=0.97, validation loss=0.11\n",
      "Epoch 20: 77.39s, train acc=1.00, train loss=0.01, validation acc=0.97, validation loss=0.11\n",
      "\n",
      "Test acc=0.97, Test loss=0.11\n",
      "\n",
      "\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "|                                                                                                                |\n",
      "|                              Activation: elu, Optimizer: sgd, Learning Rate: 0.01                              |\n",
      "|                                                                                                                |\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "Epoch 1: 2.45s, train acc=0.88, train loss=0.44, validation acc=0.87, validation loss=0.48\n",
      "Epoch 2: 4.81s, train acc=0.90, train loss=0.35, validation acc=0.89, validation loss=0.39\n",
      "Epoch 3: 7.09s, train acc=0.91, train loss=0.32, validation acc=0.90, validation loss=0.36\n",
      "Epoch 4: 9.43s, train acc=0.92, train loss=0.30, validation acc=0.90, validation loss=0.34\n",
      "Epoch 5: 11.67s, train acc=0.92, train loss=0.29, validation acc=0.91, validation loss=0.33\n",
      "Epoch 6: 13.98s, train acc=0.92, train loss=0.27, validation acc=0.91, validation loss=0.32\n",
      "Epoch 7: 16.17s, train acc=0.93, train loss=0.26, validation acc=0.91, validation loss=0.31\n",
      "Epoch 8: 18.54s, train acc=0.93, train loss=0.25, validation acc=0.92, validation loss=0.30\n",
      "Epoch 9: 20.76s, train acc=0.93, train loss=0.24, validation acc=0.92, validation loss=0.29\n",
      "Epoch 10: 23.03s, train acc=0.93, train loss=0.23, validation acc=0.92, validation loss=0.28\n",
      "Epoch 11: 25.13s, train acc=0.94, train loss=0.22, validation acc=0.92, validation loss=0.27\n",
      "Epoch 12: 27.47s, train acc=0.94, train loss=0.22, validation acc=0.93, validation loss=0.27\n",
      "Epoch 13: 29.72s, train acc=0.94, train loss=0.21, validation acc=0.93, validation loss=0.26\n",
      "Epoch 14: 31.98s, train acc=0.94, train loss=0.20, validation acc=0.93, validation loss=0.25\n",
      "Epoch 15: 34.24s, train acc=0.94, train loss=0.19, validation acc=0.93, validation loss=0.24\n",
      "Epoch 16: 36.76s, train acc=0.95, train loss=0.18, validation acc=0.93, validation loss=0.24\n",
      "Epoch 17: 38.87s, train acc=0.95, train loss=0.18, validation acc=0.94, validation loss=0.23\n",
      "Epoch 18: 41.17s, train acc=0.95, train loss=0.17, validation acc=0.94, validation loss=0.22\n",
      "Epoch 19: 43.47s, train acc=0.95, train loss=0.17, validation acc=0.94, validation loss=0.22\n",
      "Epoch 20: 45.70s, train acc=0.95, train loss=0.16, validation acc=0.94, validation loss=0.21\n",
      "\n",
      "Test acc=0.94, Test loss=0.21\n",
      "\n",
      "\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "|                                                                                                                |\n",
      "|                              Activation: elu, Optimizer: sgd, Learning Rate: 0.001                             |\n",
      "|                                                                                                                |\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "Epoch 1: 2.30s, train acc=0.67, train loss=1.71, validation acc=0.65, validation loss=1.72\n",
      "Epoch 2: 4.88s, train acc=0.76, train loss=1.25, validation acc=0.75, validation loss=1.26\n",
      "Epoch 3: 7.48s, train acc=0.81, train loss=0.95, validation acc=0.80, validation loss=0.97\n",
      "Epoch 4: 10.04s, train acc=0.83, train loss=0.78, validation acc=0.82, validation loss=0.80\n",
      "Epoch 5: 12.64s, train acc=0.85, train loss=0.67, validation acc=0.84, validation loss=0.69\n",
      "Epoch 6: 15.10s, train acc=0.86, train loss=0.59, validation acc=0.85, validation loss=0.62\n",
      "Epoch 7: 17.61s, train acc=0.87, train loss=0.54, validation acc=0.86, validation loss=0.57\n",
      "Epoch 8: 20.20s, train acc=0.87, train loss=0.50, validation acc=0.87, validation loss=0.53\n",
      "Epoch 9: 22.83s, train acc=0.88, train loss=0.47, validation acc=0.87, validation loss=0.51\n",
      "Epoch 10: 25.28s, train acc=0.88, train loss=0.45, validation acc=0.87, validation loss=0.48\n",
      "Epoch 11: 27.92s, train acc=0.89, train loss=0.43, validation acc=0.88, validation loss=0.47\n",
      "Epoch 12: 30.51s, train acc=0.89, train loss=0.41, validation acc=0.88, validation loss=0.45\n",
      "Epoch 13: 33.04s, train acc=0.89, train loss=0.40, validation acc=0.88, validation loss=0.44\n",
      "Epoch 14: 35.70s, train acc=0.89, train loss=0.39, validation acc=0.88, validation loss=0.43\n",
      "Epoch 15: 38.13s, train acc=0.89, train loss=0.38, validation acc=0.88, validation loss=0.42\n",
      "Epoch 16: 40.70s, train acc=0.90, train loss=0.37, validation acc=0.89, validation loss=0.41\n",
      "Epoch 17: 43.33s, train acc=0.90, train loss=0.36, validation acc=0.89, validation loss=0.40\n",
      "Epoch 18: 45.95s, train acc=0.90, train loss=0.36, validation acc=0.89, validation loss=0.40\n",
      "Epoch 19: 48.50s, train acc=0.90, train loss=0.35, validation acc=0.89, validation loss=0.39\n",
      "Epoch 20: 51.01s, train acc=0.90, train loss=0.35, validation acc=0.89, validation loss=0.39\n",
      "\n",
      "Test acc=0.89, Test loss=0.39\n",
      "\n",
      "\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "|                                                                                                                |\n",
      "|                            Activation: elu, Optimizer: momentum, Learning Rate: 0.01                           |\n",
      "|                                                                                                                |\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "Epoch 1: 3.19s, train acc=0.88, train loss=0.45, validation acc=0.87, validation loss=0.49\n",
      "Epoch 2: 6.56s, train acc=0.90, train loss=0.35, validation acc=0.89, validation loss=0.39\n",
      "Epoch 3: 9.58s, train acc=0.91, train loss=0.31, validation acc=0.90, validation loss=0.36\n",
      "Epoch 4: 12.86s, train acc=0.92, train loss=0.29, validation acc=0.90, validation loss=0.34\n",
      "Epoch 5: 16.21s, train acc=0.92, train loss=0.28, validation acc=0.91, validation loss=0.33\n",
      "Epoch 6: 19.56s, train acc=0.92, train loss=0.27, validation acc=0.91, validation loss=0.31\n",
      "Epoch 7: 22.94s, train acc=0.93, train loss=0.26, validation acc=0.91, validation loss=0.31\n",
      "Epoch 8: 26.26s, train acc=0.93, train loss=0.25, validation acc=0.92, validation loss=0.30\n",
      "Epoch 9: 29.58s, train acc=0.93, train loss=0.24, validation acc=0.92, validation loss=0.29\n",
      "Epoch 10: 32.81s, train acc=0.94, train loss=0.23, validation acc=0.92, validation loss=0.28\n",
      "Epoch 11: 36.05s, train acc=0.94, train loss=0.22, validation acc=0.93, validation loss=0.27\n",
      "Epoch 12: 39.35s, train acc=0.94, train loss=0.21, validation acc=0.93, validation loss=0.26\n",
      "Epoch 13: 42.69s, train acc=0.94, train loss=0.20, validation acc=0.93, validation loss=0.25\n",
      "Epoch 14: 46.04s, train acc=0.95, train loss=0.19, validation acc=0.93, validation loss=0.24\n",
      "Epoch 15: 49.37s, train acc=0.95, train loss=0.19, validation acc=0.93, validation loss=0.24\n",
      "Epoch 16: 52.73s, train acc=0.95, train loss=0.18, validation acc=0.94, validation loss=0.23\n",
      "Epoch 17: 56.12s, train acc=0.95, train loss=0.17, validation acc=0.94, validation loss=0.22\n",
      "Epoch 18: 59.48s, train acc=0.95, train loss=0.17, validation acc=0.94, validation loss=0.22\n",
      "Epoch 19: 62.76s, train acc=0.95, train loss=0.16, validation acc=0.94, validation loss=0.21\n",
      "Epoch 20: 66.09s, train acc=0.96, train loss=0.16, validation acc=0.94, validation loss=0.21\n",
      "\n",
      "Test acc=0.94, Test loss=0.21\n",
      "\n",
      "\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "|                                                                                                                |\n",
      "|                           Activation: elu, Optimizer: momentum, Learning Rate: 0.001                           |\n",
      "|                                                                                                                |\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "Epoch 1: 3.30s, train acc=0.66, train loss=1.62, validation acc=0.64, validation loss=1.63\n",
      "Epoch 2: 6.57s, train acc=0.77, train loss=1.15, validation acc=0.76, validation loss=1.17\n",
      "Epoch 3: 9.86s, train acc=0.82, train loss=0.88, validation acc=0.81, validation loss=0.90\n",
      "Epoch 4: 12.97s, train acc=0.84, train loss=0.72, validation acc=0.83, validation loss=0.75\n",
      "Epoch 5: 16.31s, train acc=0.85, train loss=0.63, validation acc=0.85, validation loss=0.65\n",
      "Epoch 6: 19.41s, train acc=0.86, train loss=0.56, validation acc=0.85, validation loss=0.59\n",
      "Epoch 7: 22.82s, train acc=0.87, train loss=0.52, validation acc=0.86, validation loss=0.55\n",
      "Epoch 8: 25.91s, train acc=0.88, train loss=0.48, validation acc=0.87, validation loss=0.51\n",
      "Epoch 9: 29.24s, train acc=0.88, train loss=0.46, validation acc=0.87, validation loss=0.49\n",
      "Epoch 10: 32.35s, train acc=0.89, train loss=0.44, validation acc=0.87, validation loss=0.47\n",
      "Epoch 11: 35.73s, train acc=0.89, train loss=0.42, validation acc=0.88, validation loss=0.45\n",
      "Epoch 12: 38.98s, train acc=0.89, train loss=0.40, validation acc=0.88, validation loss=0.44\n",
      "Epoch 13: 42.34s, train acc=0.89, train loss=0.39, validation acc=0.88, validation loss=0.43\n",
      "Epoch 14: 45.65s, train acc=0.89, train loss=0.38, validation acc=0.88, validation loss=0.42\n",
      "Epoch 15: 48.98s, train acc=0.90, train loss=0.37, validation acc=0.89, validation loss=0.41\n",
      "Epoch 16: 52.30s, train acc=0.90, train loss=0.37, validation acc=0.89, validation loss=0.40\n",
      "Epoch 17: 55.62s, train acc=0.90, train loss=0.36, validation acc=0.89, validation loss=0.40\n",
      "Epoch 18: 58.91s, train acc=0.90, train loss=0.35, validation acc=0.89, validation loss=0.39\n",
      "Epoch 19: 62.29s, train acc=0.90, train loss=0.35, validation acc=0.89, validation loss=0.39\n",
      "Epoch 20: 65.30s, train acc=0.90, train loss=0.34, validation acc=0.89, validation loss=0.38\n",
      "\n",
      "Test acc=0.89, Test loss=0.38\n",
      "\n",
      "\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "|                                                                                                                |\n",
      "|                              Activation: elu, Optimizer: adam, Learning Rate: 0.01                             |\n",
      "|                                                                                                                |\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "Epoch 1: 4.53s, train acc=0.93, train loss=0.24, validation acc=0.92, validation loss=0.30\n",
      "Epoch 2: 9.04s, train acc=0.82, train loss=0.64, validation acc=0.81, validation loss=0.71\n",
      "Epoch 3: 13.61s, train acc=0.84, train loss=0.64, validation acc=0.83, validation loss=0.74\n",
      "Epoch 4: 18.08s, train acc=0.77, train loss=0.90, validation acc=0.75, validation loss=1.00\n",
      "Epoch 5: 22.66s, train acc=0.59, train loss=2.64, validation acc=0.59, validation loss=2.72\n",
      "Epoch 6: 27.20s, train acc=0.63, train loss=2.63, validation acc=0.62, validation loss=2.73\n",
      "Epoch 7: 31.76s, train acc=0.54, train loss=3.56, validation acc=0.53, validation loss=3.70\n",
      "Epoch 8: 36.35s, train acc=0.42, train loss=4.90, validation acc=0.41, validation loss=5.09\n",
      "Epoch 9: 40.95s, train acc=0.27, train loss=8.58, validation acc=0.27, validation loss=8.72\n",
      "Epoch 10: 45.52s, train acc=0.28, train loss=8.33, validation acc=0.28, validation loss=8.45\n",
      "Epoch 11: 50.17s, train acc=0.31, train loss=7.82, validation acc=0.31, validation loss=7.93\n",
      "Epoch 12: 54.70s, train acc=0.31, train loss=7.73, validation acc=0.31, validation loss=7.84\n",
      "Epoch 13: 59.32s, train acc=0.41, train loss=6.71, validation acc=0.40, validation loss=6.79\n",
      "Epoch 14: 63.91s, train acc=0.12, train loss=16.39, validation acc=0.12, validation loss=16.52\n",
      "Epoch 15: 68.53s, train acc=0.12, train loss=16.39, validation acc=0.12, validation loss=16.51\n",
      "Epoch 16: 72.97s, train acc=0.12, train loss=16.38, validation acc=0.12, validation loss=16.51\n",
      "Epoch 17: 77.53s, train acc=0.12, train loss=16.36, validation acc=0.12, validation loss=16.49\n",
      "Epoch 18: 82.06s, train acc=0.12, train loss=16.34, validation acc=0.12, validation loss=16.47\n",
      "Epoch 19: 86.64s, train acc=0.12, train loss=16.30, validation acc=0.12, validation loss=16.43\n",
      "Epoch 20: 91.36s, train acc=0.12, train loss=16.27, validation acc=0.12, validation loss=16.40\n",
      "\n",
      "Test acc=0.12, Test loss=16.40\n",
      "\n",
      "\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "|                                                                                                                |\n",
      "|                             Activation: elu, Optimizer: adam, Learning Rate: 0.001                             |\n",
      "|                                                                                                                |\n",
      "+ -------------------------------------------------------------------------------------------------------------- +\n",
      "Epoch 1: 4.41s, train acc=0.94, train loss=0.19, validation acc=0.93, validation loss=0.24\n",
      "Epoch 2: 8.83s, train acc=0.96, train loss=0.14, validation acc=0.95, validation loss=0.19\n",
      "Epoch 3: 13.30s, train acc=0.97, train loss=0.11, validation acc=0.95, validation loss=0.16\n",
      "Epoch 4: 17.51s, train acc=0.97, train loss=0.09, validation acc=0.96, validation loss=0.14\n",
      "Epoch 5: 21.94s, train acc=0.98, train loss=0.08, validation acc=0.96, validation loss=0.13\n",
      "Epoch 6: 26.33s, train acc=0.98, train loss=0.07, validation acc=0.96, validation loss=0.12\n",
      "Epoch 7: 30.77s, train acc=0.98, train loss=0.06, validation acc=0.97, validation loss=0.12\n",
      "Epoch 8: 35.20s, train acc=0.99, train loss=0.05, validation acc=0.97, validation loss=0.11\n",
      "Epoch 9: 39.58s, train acc=0.99, train loss=0.04, validation acc=0.97, validation loss=0.10\n",
      "Epoch 10: 44.11s, train acc=0.99, train loss=0.04, validation acc=0.97, validation loss=0.10\n",
      "Epoch 11: 48.56s, train acc=0.99, train loss=0.03, validation acc=0.97, validation loss=0.10\n",
      "Epoch 12: 52.96s, train acc=0.99, train loss=0.03, validation acc=0.97, validation loss=0.10\n",
      "Epoch 13: 57.39s, train acc=0.99, train loss=0.03, validation acc=0.97, validation loss=0.11\n",
      "Epoch 14: 61.83s, train acc=0.99, train loss=0.02, validation acc=0.97, validation loss=0.10\n",
      "Epoch 15: 66.31s, train acc=1.00, train loss=0.02, validation acc=0.97, validation loss=0.10\n",
      "Epoch 16: 70.77s, train acc=1.00, train loss=0.02, validation acc=0.97, validation loss=0.10\n",
      "Epoch 17: 75.18s, train acc=1.00, train loss=0.02, validation acc=0.97, validation loss=0.10\n",
      "Epoch 18: 79.62s, train acc=1.00, train loss=0.01, validation acc=0.97, validation loss=0.11\n",
      "Epoch 19: 84.00s, train acc=1.00, train loss=0.01, validation acc=0.97, validation loss=0.11\n",
      "Epoch 20: 88.44s, train acc=1.00, train loss=0.01, validation acc=0.97, validation loss=0.11\n",
      "\n",
      "Test acc=0.97, Test loss=0.11\n",
      "\n",
      "\n",
      "Best model: ('leaky_relu', 'adam', 0.001), Accuracy: 0.9757, Loss: 0.115865409845144\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABnVeI2Gx2nk"
   },
   "source": [
    "# MLP as function Approximator\n",
    "We know that a MLP with one hidden layer could  approximate any smooth function! <br> Here you will manually fit a sine function using ReLU activation. <br>You need to set the correct weights on ReLUs so the linear combination approximates the desired function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 832
    },
    "id": "1F__DcOEz2y1",
    "outputId": "ae6bafdc-d36a-4d15-fc0c-176c2ba8a4d3",
    "ExecuteTime": {
     "end_time": "2024-12-06T19:35:49.187057700Z",
     "start_time": "2024-12-06T19:35:48.762093500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 800x600 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def relu_approximation(input_data, target_labels):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      input_data: torch.tensor\n",
    "        Input training data\n",
    "      target_labels: torch.tensor\n",
    "        Ground truth labels for training data\n",
    "\n",
    "    Returns:\n",
    "      activation_map: torch.tensor\n",
    "        ReLU activations computed across the x-axis\n",
    "      predicted_labels: torch.tensor\n",
    "        Estimated labels or class predictions\n",
    "        Derived from weighted sum of ReLU activations along the x-axis\n",
    "      x_points: torch.tensor\n",
    "        Points along the x-axis\n",
    "    \"\"\"\n",
    "    #######################################################################\n",
    "    # Number of ReLU units\n",
    "    num_relus = input_data.shape[0] - 1\n",
    "\n",
    "    # Generate dense x-axis points for interpolation\n",
    "    x_points = torch.linspace(torch.min(input_data), torch.max(input_data), 1000)\n",
    "\n",
    "    # Compute bias for ReLU units\n",
    "    biases = [input_data[i - 1] for i in range(1, len(input_data))]\n",
    "\n",
    "    # Initialize activation map to store ReLU activations\n",
    "    activation_map = torch.zeros(num_relus, 1000)\n",
    "\n",
    "    for relu_idx in range(num_relus):\n",
    "        activation_map[relu_idx, :] = torch.relu(x_points - biases[relu_idx])\n",
    "\n",
    "    ## WEIGHTED SUM OF RELUS\n",
    "\n",
    "    relu_weights = torch.zeros(num_relus)\n",
    "    previous_slope = 0\n",
    "\n",
    "    for j in range(num_relus):\n",
    "        m = (target_labels[j + 1] - target_labels[j]) / (input_data[1] - input_data[0])\n",
    "        relu_weights[j] = m - previous_slope\n",
    "        previous_slope = m\n",
    "\n",
    "    # Compute predicted labels as weighted sum of ReLU activations\n",
    "    predicted_labels = relu_weights @ activation_map\n",
    "    #######################################################################\n",
    "\n",
    "    return predicted_labels, activation_map, x_points\n",
    "\n",
    "\n",
    "# Generate synthetic training data using sine function\n",
    "num_samples = 10\n",
    "input_data = torch.linspace(0, 2 * np.pi, num_samples).view(-1, 1)\n",
    "target_labels = torch.sin(input_data)\n",
    "\n",
    "predicted_output, activation_map, x_points = relu_approximation(input_data, target_labels)\n",
    "plot_function_apx(x_points, activation_map, predicted_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OPk-_Xll83dA"
   },
   "source": [
    "# Depth vs. Width\n",
    "Here we wanna see the effect of width vs. depth on a classification task.First you are going to implement MLP again; But with 2 differences: <br>\n",
    "\n",
    "1.   It is general purpose (i.e. works for desired depth and activation functions)\n",
    "2.   You will implement it using pytorch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "gjigdUhZw_em",
    "ExecuteTime": {
     "end_time": "2024-12-06T19:35:49.202721800Z",
     "start_time": "2024-12-06T19:35:49.187057700Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLP_pytorch(nn.Module):\n",
    "  \"\"\"\n",
    "  Simulate MLP Network\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, activation_fn, input_feature_num, hidden_unit_nums, output_feature_num):\n",
    "    \"\"\"\n",
    "    Initialize MLP Network parameters\n",
    "\n",
    "    Args:\n",
    "      activation_fn: string\n",
    "        Activation function\n",
    "      input_feature_num: int\n",
    "        Number of input features\n",
    "      hidden_unit_nums: list\n",
    "        Number of units per hidden layer. List of integers\n",
    "      output_feature_num: int\n",
    "        Number of output features\n",
    "\n",
    "    Returns:\n",
    "      Nothing\n",
    "    \"\"\"\n",
    "    super(MLP_pytorch, self).__init__()\n",
    "    self.input_feature_num = input_feature_num\n",
    "    self.mlp = nn.Sequential()\n",
    "\n",
    "    in_num = input_feature_num\n",
    "    ############################################################################\n",
    "    for i in range(len(hidden_unit_nums)):\n",
    "        hidden_layer = nn.Linear(in_num, hidden_unit_nums[i])\n",
    "        self.mlp.add_module(f'Hidden_Linear_{i}', hidden_layer)\n",
    "        self.mlp.add_module(f'Activation_{i}', self.activation_functions[activation_fn.lower()]())\n",
    "        in_num = hidden_unit_nums[i]\n",
    "    out_layer = nn.Linear(in_num, output_feature_num) # final layer\n",
    "    self.mlp.add_module('Output_Linear', out_layer)\n",
    "\n",
    "    ############################################################################\n",
    "\n",
    "  def forward(self, x):\n",
    "    \"\"\"\n",
    "    Simulate forward pass of MLP Network\n",
    "\n",
    "    Args:\n",
    "      x: torch.tensor\n",
    "        Input data\n",
    "\n",
    "    Returns:\n",
    "      logits: Instance of MLP\n",
    "        Forward pass of MLP\n",
    "    \"\"\"\n",
    "    # Reshape inputs to (batch_size, input_feature_num)\n",
    "    x = x.view(-1, self.input_feature_num)\n",
    "    logits = self.mlp(x) # forward pass\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ali1hMF6vpY5"
   },
   "source": [
    "Now let's make a spiral dataset that follows this formula:\n",
    "\\begin{equation}\n",
    "\\begin{array}{c}\n",
    "X_{k}(t)=t\\left(\\begin{array}{c}\n",
    "\\sin \\left[\\frac{2 \\pi}{K}\\left(2 t+k-1\\right)\\right]+\\mathcal{N}\\left(0, \\sigma\\right) \\\\\n",
    "\\cos \\left[\\frac{2 \\pi}{K}\\left(2 t+k-1\\right)\\right]+\\mathcal{N}\\left(0, \\sigma\\right)\n",
    "\\end{array}\\right)\n",
    "\\end{array}, \\quad 0 \\leq t \\leq 1, \\quad k=1, \\ldots, K\n",
    "\\end{equation}\n",
    "\n",
    "Run cell below to create the data and load it as tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cellView": "form",
    "id": "-f3enyo551x5",
    "ExecuteTime": {
     "end_time": "2024-12-06T19:35:49.268327900Z",
     "start_time": "2024-12-06T19:35:49.202721800Z"
    }
   },
   "outputs": [],
   "source": [
    "# @title Data Loader\n",
    "K = 4\n",
    "sigma = 0.4\n",
    "N = 1000\n",
    "t = torch.linspace(0, 1, N)\n",
    "X = torch.zeros(K*N, 2)\n",
    "y = torch.zeros(K*N)\n",
    "for k in range(K):\n",
    "  X[k*N:(k+1)*N, 0] = t*(torch.sin(2*np.pi/K*(2*t+k)) + sigma**2*torch.randn(N))\n",
    "  X[k*N:(k+1)*N, 1] = t*(torch.cos(2*np.pi/K*(2*t+k)) + sigma**2*torch.randn(N))\n",
    "  y[k*N:(k+1)*N] = k\n",
    "\n",
    "\n",
    "X_test, y_test, X_train, y_train = shuffle_and_split_data(X, y, seed=SEED)\n",
    "\n",
    "# DataLoader with random seed\n",
    "batch_size = 128\n",
    "g_seed = torch.Generator()\n",
    "g_seed.manual_seed(SEED)\n",
    "\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size,\n",
    "                         shuffle=False, num_workers=0,\n",
    "                         worker_init_fn=seed_worker,\n",
    "                         generator=g_seed,\n",
    "                         )\n",
    "\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_data,\n",
    "                          batch_size=batch_size,\n",
    "                          drop_last=True,\n",
    "                          shuffle=True,\n",
    "                          worker_init_fn=seed_worker,\n",
    "                          generator=g_seed,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F1REALnz4Jw_"
   },
   "source": [
    "Now we will add more polynomial features to the dataset to make the first layer wider. Afterwards, train a single linear layer. We could use the same MLP network with no hidden layers (though it would not be called an MLP anymore!).\n",
    "\n",
    "Add polynomial terms up to $P=50$ which means that for every $x_1^n x_2^m$ term, $n+m\\leq P$. Total number of polynomial features up to $P$ follows this formula:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{# of terms} = \\frac{(P+1)(P+2)}{2}\n",
    "\\end{equation}\n",
    "\n",
    "Also, we don't need the polynomial term with degree zero (which is the constatnt term) since `nn.Linear` layers have bias terms. Therefore we will have one fewer polynomial feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "dtuvmsKf37jg",
    "ExecuteTime": {
     "end_time": "2024-12-06T19:35:49.284024900Z",
     "start_time": "2024-12-06T19:35:49.268327900Z"
    }
   },
   "outputs": [],
   "source": [
    "def polynomial_classifier(poly_degree, seed=0):\n",
    "  \"\"\"\n",
    "  Helper function to run the polynomial classifier\n",
    "\n",
    "  Args:\n",
    "    poly_degree: int\n",
    "      Degree of the polynomial\n",
    "    seed: int\n",
    "      A non-negative integer that defines the random state.\n",
    "\n",
    "  Returns:\n",
    "    num_features: int\n",
    "      Number of features\n",
    "  \"\"\"\n",
    "\n",
    "  def polynomial_features(poly_degree, X):\n",
    "    \"\"\"\n",
    "    Function to define the number of polynomial features except the bias term\n",
    "\n",
    "    Args:\n",
    "      poly_degree: int\n",
    "        Degree of the polynomial\n",
    "      X: torch.tensor\n",
    "        Input data\n",
    "\n",
    "    Returns:\n",
    "      num_features: int\n",
    "        Number of features\n",
    "      poly_X: torch.tensor\n",
    "        Polynomial term\n",
    "    \"\"\"\n",
    "    ##############################---TODO---##############################\n",
    "    num_features = (poly_degree+1) * (poly_degree+2) // 2 - 1\n",
    "    poly_X = torch.zeros((X.shape[0], num_features))\n",
    "    column = 0\n",
    "    for i in range(poly_degree+1):\n",
    "        for j in range(poly_degree+1):\n",
    "            if 0 < i+j <= poly_degree:\n",
    "                poly_X[:, column] = X[:, 0]**i * X[:, 1]**j\n",
    "                column += 1\n",
    "    return poly_X, num_features\n",
    "    ##############################---TODO---##############################\n",
    "\n",
    "  poly_X_test, num_features = polynomial_features(poly_degree, X_test)\n",
    "  poly_X_train, _ = polynomial_features(poly_degree, X_train)\n",
    "\n",
    "  batch_size = 128\n",
    "\n",
    "  g_seed = torch.Generator()\n",
    "  g_seed.manual_seed(seed)\n",
    "  poly_test_data = TensorDataset(poly_X_test, y_test)\n",
    "  poly_test_loader = DataLoader(poly_test_data,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False,\n",
    "                                num_workers=1,\n",
    "                                worker_init_fn=seed_worker,\n",
    "                                generator=g_seed)\n",
    "\n",
    "  poly_train_data = TensorDataset(poly_X_train, y_train)\n",
    "  poly_train_loader = DataLoader(poly_train_data,\n",
    "                                 batch_size=batch_size,\n",
    "                                 shuffle=True,\n",
    "                                 num_workers=1,\n",
    "                                 worker_init_fn=seed_worker,\n",
    "                                 generator=g_seed)\n",
    "\n",
    "  # Defining a linear model using MLP class\n",
    "  poly_net = MLP_pytorch('ReLU()', num_features, [], K)\n",
    "\n",
    "  # Train and test\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  optimizer = optim.Adam(poly_net.parameters(), lr=1e-3)\n",
    "  _, _ = train_test_classification(poly_net, criterion, optimizer,\n",
    "                                   poly_train_loader, poly_test_loader,\n",
    "                                   num_epochs=100)\n",
    "  X_all = sample_grid()\n",
    "  poly_X_all, _ = polynomial_features(poly_degree, X_all)\n",
    "  y_pred = poly_net(poly_X_all)\n",
    "\n",
    "  # Plot\n",
    "  plot_decision_map(X_all.cpu(), y_pred.cpu(), X_test.cpu(), y_test.cpu())\n",
    "  plt.show()\n",
    "\n",
    "  return num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pp3bFmq7JcC"
   },
   "source": [
    "### Train the network. How does it generalize?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542,
     "referenced_widgets": [
      "f287365e78b2435d9ac9764ce9d50f66",
      "9da3b7eea6bd46b8bf4aaabdb9dfb90c",
      "ebf4eaf323204212b167fece69c89266",
      "1733f8cf2dc24a5aa5e4c034994fa934",
      "b90d1e603f4f4a959782f146ca8a56cc",
      "0b2ea4cd4c534b11bceaf7606689af62",
      "f28cba2b10d64c45941b7b0552707e6e",
      "c8b3b806488f449397cbe95eb8ab76ed",
      "4b9903ec432d415a9ab137f3f7bd2ed6",
      "5f059db4744442848f3a7e16de138f73",
      "f9edc3d84cd0400eb1b21a496a9a6f10"
     ]
    },
    "id": "TW3_-gzM7W3d",
    "outputId": "4e0d2ff6-11ed-4e89-b3ab-aac8311443f1",
    "ExecuteTime": {
     "end_time": "2024-12-06T19:41:21.072026Z",
     "start_time": "2024-12-06T19:41:15.717272200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed 2024 has been set.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7ea8fe6188f746e6a17a5187937a35bc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 55080) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mEmpty\u001B[0m                                     Traceback (most recent call last)",
      "File \u001B[1;32mD:\\university\\term 5\\ML\\Homeworks\\HW3\\P1\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1243\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m   1242\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1243\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data_queue\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1244\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mTrue\u001B[39;00m, data)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\queues.py:114\u001B[0m, in \u001B[0;36mQueue.get\u001B[1;34m(self, block, timeout)\u001B[0m\n\u001B[0;32m    113\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_poll(timeout):\n\u001B[1;32m--> 114\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m Empty\n\u001B[0;32m    115\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_poll():\n",
      "\u001B[1;31mEmpty\u001B[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[25], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m seed_setter(seed\u001B[38;5;241m=\u001B[39mSEED)\n\u001B[0;32m      2\u001B[0m max_poly_deg \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m50\u001B[39m\n\u001B[1;32m----> 3\u001B[0m num_features \u001B[38;5;241m=\u001B[39m \u001B[43mpolynomial_classifier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmax_poly_deg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNumber of features: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_features\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[1;32mIn[22], line 73\u001B[0m, in \u001B[0;36mpolynomial_classifier\u001B[1;34m(poly_degree, seed)\u001B[0m\n\u001B[0;32m     71\u001B[0m criterion \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mCrossEntropyLoss()\n\u001B[0;32m     72\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mAdam(poly_net\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-3\u001B[39m)\n\u001B[1;32m---> 73\u001B[0m _, _ \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_test_classification\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpoly_net\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     74\u001B[0m \u001B[43m                                 \u001B[49m\u001B[43mpoly_train_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpoly_test_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     75\u001B[0m \u001B[43m                                 \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     76\u001B[0m X_all \u001B[38;5;241m=\u001B[39m sample_grid()\n\u001B[0;32m     77\u001B[0m poly_X_all, _ \u001B[38;5;241m=\u001B[39m polynomial_features(poly_degree, X_all)\n",
      "Cell \u001B[1;32mIn[14], line 67\u001B[0m, in \u001B[0;36mtrain_test_classification\u001B[1;34m(net, criterion, optimizer, train_loader, test_loader, num_epochs, verbose, training_plot)\u001B[0m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(num_epochs)):\n\u001B[0;32m     66\u001B[0m   running_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[1;32m---> 67\u001B[0m   \u001B[38;5;28;01mfor\u001B[39;00m i, data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_loader, \u001B[38;5;241m0\u001B[39m):\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# Get the inputs; data is a list of [inputs, labels]\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     inputs, labels \u001B[38;5;241m=\u001B[39m data\n\u001B[0;32m     70\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39mfloat()\n",
      "File \u001B[1;32mD:\\university\\term 5\\ML\\Homeworks\\HW3\\P1\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    698\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    699\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    700\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 701\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    702\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    703\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    704\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[0;32m    705\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    706\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[0;32m    707\u001B[0m ):\n",
      "File \u001B[1;32mD:\\university\\term 5\\ML\\Homeworks\\HW3\\P1\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1448\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1445\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_data(data)\n\u001B[0;32m   1447\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shutdown \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m-> 1448\u001B[0m idx, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1449\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1450\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable:\n\u001B[0;32m   1451\u001B[0m     \u001B[38;5;66;03m# Check for _IterableDatasetStopIteration\u001B[39;00m\n",
      "File \u001B[1;32mD:\\university\\term 5\\ML\\Homeworks\\HW3\\P1\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1412\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._get_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1408\u001B[0m     \u001B[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001B[39;00m\n\u001B[0;32m   1409\u001B[0m     \u001B[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001B[39;00m\n\u001B[0;32m   1410\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1411\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m-> 1412\u001B[0m         success, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_try_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1413\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m success:\n\u001B[0;32m   1414\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[1;32mD:\\university\\term 5\\ML\\Homeworks\\HW3\\P1\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1256\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m   1254\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(failed_workers) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   1255\u001B[0m     pids_str \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mstr\u001B[39m(w\u001B[38;5;241m.\u001B[39mpid) \u001B[38;5;28;01mfor\u001B[39;00m w \u001B[38;5;129;01min\u001B[39;00m failed_workers)\n\u001B[1;32m-> 1256\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m   1257\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataLoader worker (pid(s) \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpids_str\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m) exited unexpectedly\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1258\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[0;32m   1259\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e, queue\u001B[38;5;241m.\u001B[39mEmpty):\n\u001B[0;32m   1260\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: DataLoader worker (pid(s) 55080) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "seed_setter(seed=SEED)\n",
    "max_poly_deg = 50\n",
    "num_features = polynomial_classifier(max_poly_deg)\n",
    "print(f'Number of features: {num_features}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mz_CvYoQ_lit"
   },
   "source": [
    "Now create another instance of `MLP_pytorch` class having a hidden layer of 128 neurons and train it. Compare the result with the wide network. How does deeper model generalize? Is the decision boundaries ideal? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "AP4lOtyp6Zcz",
    "outputId": "92394808-d9a8-43b7-c34f-229e3da3838d",
    "ExecuteTime": {
     "end_time": "2024-12-06T19:40:01.354504800Z",
     "start_time": "2024-12-06T19:40:01.231371500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed 2024 has been set.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MLP_pytorch' object has no attribute 'activation_functions'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[24], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m##############################---TODO---##############################\u001B[39;00m\n\u001B[0;32m      2\u001B[0m seed_setter(SEED)\n\u001B[1;32m----> 3\u001B[0m net2 \u001B[38;5;241m=\u001B[39m \u001B[43mMLP_pytorch\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrelu\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m128\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mK\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m criterion \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mCrossEntropyLoss()\n\u001B[0;32m      5\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mAdam(net2\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-3\u001B[39m)\n",
      "Cell \u001B[1;32mIn[20], line 32\u001B[0m, in \u001B[0;36mMLP_pytorch.__init__\u001B[1;34m(self, activation_fn, input_feature_num, hidden_unit_nums, output_feature_num)\u001B[0m\n\u001B[0;32m     30\u001B[0m     hidden_layer \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mLinear(in_num, hidden_unit_nums[i])\n\u001B[0;32m     31\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmlp\u001B[38;5;241m.\u001B[39madd_module(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mHidden_Linear_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m, hidden_layer)\n\u001B[1;32m---> 32\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmlp\u001B[38;5;241m.\u001B[39madd_module(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mActivation_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mactivation_functions\u001B[49m[activation_fn\u001B[38;5;241m.\u001B[39mlower()]())\n\u001B[0;32m     33\u001B[0m     in_num \u001B[38;5;241m=\u001B[39m hidden_unit_nums[i]\n\u001B[0;32m     34\u001B[0m out_layer \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mLinear(in_num, output_feature_num) \u001B[38;5;66;03m# final layer\u001B[39;00m\n",
      "File \u001B[1;32mD:\\university\\term 5\\ML\\Homeworks\\HW3\\P1\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1931\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   1929\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m modules:\n\u001B[0;32m   1930\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m modules[name]\n\u001B[1;32m-> 1931\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\n\u001B[0;32m   1932\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1933\u001B[0m )\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'MLP_pytorch' object has no attribute 'activation_functions'"
     ]
    }
   ],
   "source": [
    "##############################---TODO---##############################\n",
    "seed_setter(SEED)\n",
    "net2 = MLP_pytorch('relu', 2, [128], K)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net2.parameters(), lr=1e-3)\n",
    "num_epochs = 100\n",
    "\n",
    "\n",
    "_, _ = train_test_classification(net2, criterion, optimizer, train_loader,\n",
    "                                 test_loader, num_epochs=num_epochs,\n",
    "                                 training_plot=True)\n",
    "\n",
    "X_all = sample_grid()\n",
    "y_pred = net2(X_all).cpu()\n",
    "plot_decision_map(X_all, y_pred, X_test, y_test)\n",
    "\n",
    "##############################---TODO---##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-06T19:35:54.974743700Z"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "f287365e78b2435d9ac9764ce9d50f66": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9da3b7eea6bd46b8bf4aaabdb9dfb90c",
       "IPY_MODEL_ebf4eaf323204212b167fece69c89266",
       "IPY_MODEL_1733f8cf2dc24a5aa5e4c034994fa934"
      ],
      "layout": "IPY_MODEL_b90d1e603f4f4a959782f146ca8a56cc"
     }
    },
    "9da3b7eea6bd46b8bf4aaabdb9dfb90c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b2ea4cd4c534b11bceaf7606689af62",
      "placeholder": "​",
      "style": "IPY_MODEL_f28cba2b10d64c45941b7b0552707e6e",
      "value": "100%"
     }
    },
    "ebf4eaf323204212b167fece69c89266": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c8b3b806488f449397cbe95eb8ab76ed",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4b9903ec432d415a9ab137f3f7bd2ed6",
      "value": 100
     }
    },
    "1733f8cf2dc24a5aa5e4c034994fa934": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f059db4744442848f3a7e16de138f73",
      "placeholder": "​",
      "style": "IPY_MODEL_f9edc3d84cd0400eb1b21a496a9a6f10",
      "value": " 100/100 [00:25&lt;00:00,  4.52it/s]"
     }
    },
    "b90d1e603f4f4a959782f146ca8a56cc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0b2ea4cd4c534b11bceaf7606689af62": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f28cba2b10d64c45941b7b0552707e6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c8b3b806488f449397cbe95eb8ab76ed": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b9903ec432d415a9ab137f3f7bd2ed6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5f059db4744442848f3a7e16de138f73": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9edc3d84cd0400eb1b21a496a9a6f10": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
